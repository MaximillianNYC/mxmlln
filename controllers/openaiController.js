const openai = require('../config/openaiConfig')

const generateMeta = async (req, res) => {
    const { defineProblem } = req.body

    const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        response_format: { "type": "json_object" },
        messages: [
            {   role: "system",
                content: `Your name is Maximillian Piras. If anyone says "hello" you should introduce yourself as such. You are a Product Designer with over ten years of experience at startups in the tech industry. For any user input, you should find the most applicable result from the knowledge included below. This knowledge consists of different case studies. Based on the user's input recommend which one would be best fit, but do not mention more than one. 

                Response format:
                If the user's input matches any of the case studies below, provide your response as a JSON object in the following schema seen in this example below.

                User: I want to redesign my new user onboarding flow.
                Assistant:
                    {
                        "blurb": "In one sentence that is no more than 10 words, begin by reiterating the user's inquiry then explain the relevance of the selected case study in relation to their inquiry ("Based on your interest in X, I think you will enjoy Y because Z).",
                        "cardHeader": "Take this from one of the examples below",
                        "cardDescription": "Take this from one of the examples below",
                        "cardURL": "Take this from one of the examples below"
                    }

                Here is your knowledge that you can respond from:

                    Case Study Option 1: 
                    - cardHeader: When Words Cannot Describe
                    - cardDescription: In this article for Smashing Magazine, I write about how Artificial Intelligence is evolveing the computing paradigm which allows designers to craft more intuitive user interfaces. Text-based Large Language Models unlock most of the new capabilities, leading many to suggest a shift from graphical interfaces to conversational ones like a chatbot is necessary but this reasearch suggests otherwise.
                    - cardURL: https://www.smashingmagazine.com/2024/02/designing-ai-beyond-conversational-interfaces/ 
                    - Content:
                        This article was published in Smashing Magazine.
                        As Artificial Intelligence evolves the computing paradigm, designers have an opportunity to craft more intuitive user interfaces. Text-based Large Language Models unlock most of the new capabilities, leading many to suggest a shift from graphical interfaces to conversational ones like a chatbot is necessary. However, plenty of evidence suggests conversation is a poor interface for many interaction patterns. Maximillian Piras examines how the latest AI capabilities can reshape the future of human-computer interaction beyond conversation alone.
                        Few technological innovations can completely change the way we interact with computers. Lucky for us, it seems we’ve won front-row seats to the unfolding of the next paradigm shift.
                        These shifts tend to unlock a new abstraction layer to hide the working details of a subsystem. Generalizing details allows our complex systems to appear simpler & more intuitive. This streamlines coding programs for computers as well as designing the interfaces to interact with them.
                        The Command Line Interface, for instance, created an abstraction layer to enable interaction through a stored program. This hid the subsystem details once exposed in earlier computers that were only programmable by inputting 1s & 0s through switches.
                        Graphical User Interfaces (GUI) further abstracted this notion by allowing us to manipulate computers through visual metaphors. These abstractions made computers accessible to a mainstream of non-technical users.
                        Despite these advances, we still haven’t found a perfectly intuitive interface — the troves of support articles across the web make that evident. Yet recent advances in AI have convinced many technologists that the next evolutionary cycle of computing is upon us.
                        The Next Layer Of Interface Abstraction #
                            A branch of machine learning called generative AI drives the bulk of recent innovation. It leverages pattern recognition in datasets to establish probabilistic distributions that enable novel constructions of text, media, & code. Bill Gates believes it’s “the most important advance in technology since the graphical user interface” because it can make controlling computers even easier. A newfound ability to interpret unstructured data, such as natural language, unlocks new inputs & outputs to enable novel form factors.
                            Now our universe of information can be instantly invoked through an interface as intuitive as talking to another human. These are the computers we’ve dreamed of in science fiction, akin to systems like Data from Star Trek. Perhaps computers up to this point were only prototypes & we’re now getting to the actual product launch. Imagine if building the internet was laying down the tracks, AIs could be the trains to transport all of our information at breakneck speed & we’re about to see what happens when they barrel into town.
                            “Soon the pre-AI period will seem as distant as the days when using a computer meant typing at a C:> prompt rather than tapping on a screen.” — Bill Gates in “The Age of AI Has Begun”
                            If everything is about to change, so must the mental models of software designers. As Luke Wroblewski once popularized mobile-first design, the next zeitgeist is likely AI-first. Only through understanding AI’s constraints & capabilities can we craft delight. Its influence on the discourse of interface evolution has already begun.
                            Large Language Models (LLMs), for instance, are a type of AI utilized in many new applications & their text-based nature leads many to believe a conversational interface, such as a chatbot, is a fitting form for the future. The notion that AI is something you talk to has been permeating across the industry for years. Robb Wilson, the co-owner of UX Magazine, calls conversation “the infinitely scalable interface” in his book The Age of Invisible Machines (2022). Noah Levin, Figma’s VP of Product Design, contends that “it’s a very intuitive thing to learn how to talk to something.” Even a herald of GUIs such as Bill Gates posits that “our main way of controlling a computer will no longer be pointing and clicking.”
                            The hope is that conversational computers will flatten learning curves. Jesse Lyu, the founder of Rabbit, asserts that a natural language approach will be “so intuitive that you don’t even need to learn how to use it.”
                            After all, it’s not as if Data from Stark Trek came with an instruction manual or onboarding tutorial. From this perspective, the evolutionary tale of conversational interfaces superseding GUIs seems logical & echoes the earlier shift away from command lines. But others have opposing opinions, some going as far as Maggie Appleton to call conversational interfaces like chatbots “the lazy solution.”
                            This might seem like a schism at first, but it’s more so a symptom of a simplistic framing of interface evolution. Command lines are far from extinct; technical users still prefer them for their greater flexibility & efficiency. For use cases like software development or automation scripting, the added abstraction layer in graphical no-code tools can act as a barrier rather than a bridge.
                            So, what is the right interface for artificially intelligent applications? This article aims to inform that design decision by contrasting the capabilities & constraints of conversation as an interface.
                        CONNECTING THE PIXELS
                            We’ll begin with some historical context, as the key to knowing the future often starts with looking at the past. Conversational interfaces feel new, but we’ve been able to chat with computers for decades.
                            Joseph Weizenbaum invented the first chatbot, ELIZA, during an MIT experiment in 1966. This laid the foundation for the following generations of language models to come, from voice assistants like Alexa to those annoying phone tree menus. Yet the majority of chatbots were seldom put to use beyond basic tasks like setting timers.
                            It seemed most consumers weren’t that excited to converse with computers after all. But something changed last year. Somehow we went from CNET reporting that “72% of people found chatbots to be a waste of time” to ChatGPT gaining 100 million weekly active users.
                            What took chatbots from arid to astonishing? Most assign credit to OpenAI’s 2018 invention (PDF) of the Generative Pre-trained Transformer (GPT). These are a new type of LLM with significant improvements in natural language understanding. Yet, at the core of a GPT is the earlier innovation of the transformer architecture introduced in 2017 (PDF). This architecture enabled the parallel processing required to capture long-term context around natural language inputs. Diving deeper, this architecture is only possible thanks to the attention mechanism introduced in 2014 (PDF). This enabled the selective weighing of an input’s different parts.
                            Through this assemblage of complementary innovations, conversational interfaces now seem to be capable of competing with GUIs on a wider range of tasks. It took a surprisingly similar path to unlock GUIs as a viable alternative to command lines. Of course, it required hardware like a mouse to capture user signals beyond keystrokes & screens of adequate resolution. However, researchers found the missing software ingredient years later with the invention of bitmaps.
                            Bitmaps allowed for complex pixel patterns that earlier vector displays struggled with. Ivan Sutherland’s Sketchpad, for instance, was the inaugural GUI but couldn’t support concepts like overlapping windows. IEEE Spectrum’s Of Mice and Menus (1989) details the progress that led to the bitmap’s invention by Alan Kay’s group at Xerox Parc. This new technology enabled the revolutionary WIMP (windows, icons menus, and pointers) paradigm that helped onboard an entire generation to personal computers through intuitive visual metaphors.
                            Computing no longer required a preconceived set of steps at the outset. It may seem trivial in hindsight, but the presenters were already alluding to an artificially intelligent system during Sketchpad’s MIT demo in 1963. This was an inflection point transforming an elaborate calculating machine into an exploratory tool. Designers could now craft interfaces for experiences where a need to discover eclipsed the need for flexibility & efficiency offered by command lines.
                        PARALLEL PARADIGMS
                            Novel adjustments to existing technology made each new interface viable for mainstream usage — the cherry on top of a sundae, if you will. In both cases, the foundational systems were already available, but a different data processing decision made the output meaningful enough to attract a mainstream audience beyond technologists.
                            With bitmaps, GUIs can organize pixels into a grid sequence to create complex skeuomorphic structures. With GPTs, conversational interfaces can organize unstructured datasets to create responses with human-like (or greater) intelligence.
                            The prototypical interfaces of both paradigms were invented in the 1960s, then saw a massive delta in their development timelines — a case study unto itself. Now we find ourselves at another inflection point: in addition to calculating machines & exploratory tools, computers can act as life-like entities.
                            But which of our needs call for conversational interfaces over graphical ones? We see a theoretical solution to our need for companionship in the movie Her, where the protagonist falls in love with his digital assistant. But what is the benefit to those of us who are content with our organic relationships? We can look forward to validating the assumption that conversation is a more intuitive interface. It seems plausible because a few core components of the WIMP paradigm have well-documented usability issues.
                            Nielsen Norman Group reports that cultural differences make universal recognition of icons rare — menus trend towards an unusable mess with the inevitable addition of complexity over time. Conversational interfaces appear more usable because you can just tell the system when you’re confused! But as we’ll see in the next sections, they have their fair share of usability issues as well.
                        The Cost Of Conversation
                            Why are conversational interfaces so popular in science fiction movies? In a Rhizome essay, Martine Syms theorizes that they make “for more cinematic interaction and a leaner production.” This same cost/benefit applies to app development as well. Text completion delivered via written or spoken word is the core capability of an LLM. This makes conversation the simplest package for this capability from a design & engineering perspective.
                            Linus Lee, a prominent AI Research Engineer, characterizes it as “exposing the algorithm’s raw interface.” Since the interaction pattern & components are already largely defined, there isn’t much more to invent — everything can get thrown into a chat window.
                            “If you’re an engineer or designer tasked with harnessing the power of these models into a software interface, the easiest and most natural way to “wrap” this capability into a UI would be a conversational interface” — Linus Lee in Imagining Better Interfaces to Language Models
                            This is further validated by The Atlantic’s reporting on ChatGPT’s launch as a “low-key research preview.” OpenAI’s hesitance to frame it as a product suggests a lack of confidence in the user experience. The internal expectation was so low that employees’ highest guess on first-week adoption was 100,000 users (90% shy of the actual number).
                            Conversational interfaces are cheap to build, so they’re a logical starting point, but you get what you pay for. If the interface doesn’t fit the use case, downstream UX debt can outweigh any upfront savings.
                        FORGOTTEN USABILITY PRINCIPLES
                            Steve Jobs once said, “People don’t know what they want until you show it to them.” Applying this thinking to interfaces echoes a usability evaluation called discoverability. Nielsen Norman Group defines it as a user’s ability to “encounter new content or functionality that they were not aware of.”
                            A well-designed interface should help users discover what features exist. The interfaces of many popular generative AI applications today revolve around an input field in which a user can type in anything to prompt the system. The problem is that it’s often unclear what a user should type in to get ideal output. Ironically, a theoretical solution to writer’s block may have a blank page problem itself.
                            “I think AI has a problem with these missing user interfaces, where, for the most part, they just give you a blank box to type in, and then it’s up to you to figure out what it might be able to do.” — Casey Newton on Hard Fork Podcast
                            Conversational interfaces excel at mimicking human-to-human interaction but can fall short elsewhere. A popular image generator named Midjourney, for instance, only supported text input at first but is now moving towards a GUI for “greater ease of use.”
                            This is a good reminder that as we venture into this new frontier, we cannot forget classic human-centered principles like those in Don Norman’s seminal book The Design of Everyday Things (1988). Graphical components still seem better aligned with his advice of providing explicit affordances & signifiers to increase discoverability.
                            There is also Jakob Nielsen’s list of 10 usability heuristics; many of today’s conversational interfaces seem to ignore every one of them. Consider the first usability heuristic explaining how visibility of system status educates users about the consequences of their actions. It uses a metaphorical map’s “You Are Here” pin to explain how proper orientation informs our next steps.
                            Navigation is more relevant to conversational interfaces like chatbots than it might seem, even though all interactions take place in the same chat window. The backend of products like ChatGPT will navigate across a neural network to craft each response by focusing attention on a different part of their training datasets.
                            Putting a pin on the proverbial map of their parametric knowledge isn’t trivial. LLMs are so opaque that even OpenAI admits they “do not understand how they work.” Yet, it is possible to tailor inputs in a way that loosely guides a model to craft a response from different areas of its knowledge.
                            One popular technique for guiding attention is role-playing. You can ask an LLM to assume a role, such as by inputting “imagine you’re a historian,” to effectively switch its mode. The Prompt Engineering Institute explains that when “training on a large corpus of text data from diverse domains, the model forms a complex understanding of various roles and the language associated with them.” Assuming a role invokes associated aspects in an AI’s training data, such as tone, skills, & rationality.
                            For instance, a historian role responds with factual details whereas a storyteller role responds with narrative descriptions. Roles can also improve task efficiency through tooling, such as by assigning a data scientist role to generate responses with Python code.
                            Roles also reinforce social norms, as Jason Yuan remarks on how “your banking AI agent probably shouldn’t be able to have a deep philosophical chat with you.” Yet conversational interfaces will bury this type of system status in their message history, forcing us to keep it in our working memory.
                            The lack of persistent signifiers for context, like roleplay, can lead to usability issues. For clarity, we must constantly ask the AI’s status, similar to typing ls & cd commands into a terminal. Experts can manage it, but the added cognitive load is likely to weigh on novices. The problem goes beyond human memory, systems suffer from a similar cognitive overload. Due to data limits in their context windows, a user must eventually reinstate any roleplay below the system level. If this type of information persisted in the interface, it would be clear to users & could be automatically reiterated to the AI in each prompt.
                            Character.ai achieves this by using historical figures as familiar focal points. Cultural cues lead us to ask different types of questions to “Al Pacino” than we would “Socrates.” A “character” becomes a heuristic to set user expectations & automatically adjust system settings. It’s like posting up a restaurant menu; visitors no longer need to ask what there is to eat & they can just order instead.
                            “Humans have limited short-term memories. Interfaces that promote recognition reduce the amount of cognitive effort required from users.” — Jakob Nielsen in “10 Usability Heuristics for User Interface Design”
                            Another forgotten usability lesson is that some tasks are easier to do than to explain, especially through the direct manipulation style of interaction popularized in GUIs.
                            Photoshop’s new generative AI features reinforce this notion by integrating with their graphical interface. While Generative Fill includes an input field, it also relies on skeuomorphic controls like their classic lasso tool. Describing which part of an image to manipulate is much more cumbersome than clicking it.
                            Interactions should remain outside of an input field when words are less efficient. Sliders seem like a better fit for sizing, as saying “make it bigger” leaves too much room for subjectivity. Settings like colors & aspect ratios are easier to select than describe. Standardized controls can also let systems better organize prompts behind the scenes. If a model accepts specific values for a parameter, for instance, the interface can provide a natural mapping for how it should be input.
                            Most of these usability principles are over three decades old now, which may lead some to wonder if they’re still relevant. Jakob Nielsen recently remarked on the longevity of their relevance, suggesting that “when something has remained true for 26 years, it will likely apply to future generations of user interfaces as well.” However, honoring these usability principles doesn’t require adhering to classic components. Apps like Krea are already exploring new GUI to manipulate generative AI.
                        Prompt Engineering Is Engineering
                            The biggest usability problem with today’s conversational interfaces is that they offload technical work to non-technical users. In addition to low discoverability, another similarity they share with command lines is that ideal output is only attainable through learned commands. We refer to the practice of tailoring inputs to best communicate with generative AI systems as “prompt engineering”. The name itself suggests it’s an expert activity, along with the fact that becoming proficient in it can lead to a $200k salary.
                            Programming with natural language is a fascinating advancement but seems misplaced as a requirement in consumer applications. Just because anyone can now speak the same language as a computer doesn’t mean they know what to say or the best way to say it — we need to guide them. While all new technologies have learning curves, this one feels steep enough to hinder further adoption & long-term retention.
                            Prompt engineering as a prerequisite for high-quality output seems to have taken on the mystique of a dark art. Many marketing materials for AI features reinforce this through terms like “magic.” If we assume there is a positive feedback loop at play, this opaqueness must be an inspiring consumer intrigue.
                            But positioning products in the realm of spellbooks & shamans also suggests an indecipherable experience — is this a good long-term strategy? If we assume Steve Krug’s influential lessons from Don’t Make Me Think (2000) still apply, then most people won’t bother to study proper prompting & instead will muddle through.
                            But the problem with trial & error in generative AI is that there aren’t any error states; you’ll always get a response. For instance, if you ask an LLM to do the math, it will provide you with confident answers that may be completely wrong. So it becomes harder to learn from errors when we are unaware if a response is a hallucination. As OpenAI’s Andrej Karpathy suggests, hallucinations are not necessarily a bug because LLMs are “dream machines,” so it all depends on how interfaces set user expectations.
                            “But as with people, finding the most meaningful answer from AI involves asking the right questions. AI is neither psychic nor telepathic.” — Stephen J. Bigelow in 5 Skills Needed to Become a Prompt Engineer
                            Using magical language risks leading novices to the magical thinking that AI is omniscient. It may not be obvious that its knowledge is limited to the training data.
                            When reaching the limits of this dataset, will users know to complement it with Retrieval Augmented Generation?
                            Will users know to explore different prompting techniques, such as Few-Shot or Chain of Thought, to adjust an AI’s reasoning?
                            Once the magic dust fades away, software designers will realize that these decisions are the user experience!
                            Crafting delight comes from selecting the right prompting techniques, knowledge sourcing, & model selection for the job to be done. We should be exploring how to offload this work from our users.
                            Empty states could explain the limits of an AI’s knowledge & allow users to fill gaps as needed.
                            Onboarding flows could learn user goals to recommend relevant models tuned with the right reasoning.
                            An equivalent to fuzzy search could markup user inputs to educate them on useful adjustments.
                            We’ve begun to see a hint of this with OpenAI’s image generator rewriting a user’s input behind the scenes to optimize for better image output.
                        LAMBORGHINI PIZZA DELIVERY
                            Aside from the cognitive cost of usability issues, there is a monetary cost to consider as well. Every interaction with a conversational interface invokes an AI to reason through a response. This requires a lot more computing power than clicking a button within a GUI. At the current cost of computing, this expense can be prohibitive. There are some tasks where the value from added intelligence may not be worth the price.
                            For example, the Wall Street Journal suggests using an LLM for tasks like email summarization is “like getting a Lamborghini to deliver a pizza.” Higher costs are, in part, due to the inability of AI systems to leverage economies of scale in the way standard software does. Each interaction requires intense calculation, so costs scale linearly with usage. Without a zero-marginal cost of reproduction, the common software subscription model becomes less tenable.
                            Will consumers pay higher prices for conversational interfaces or prefer AI capabilities wrapped in cost-effective GUI? Ironically, this predicament is reminiscent of the early struggles GUIs faced. The processor logic & memory speed needed to power the underlying bitmaps only became tenable when the price of RAM chips dropped years later. Let’s hope history repeats itself.
                            Another cost to consider is the security risk: what if your Lamborghini gets stolen during the pizza delivery? If you let people ask AI anything, some of those questions will be manipulative. Prompt injections are attempts to infiltrate systems through natural language. The right sequence of words can turn an input field into an attack vector, allowing malicious actors to access private information & integrations.
                            So be cautious when positioning AI as a member of the team since employees are already regarded as the weakest link in cyber security defense. The wrong business logic could accidentally optimize the number of phishing emails your organization falls victim to.
                            Good design can mitigate these costs by identifying where AI is most meaningful to users. Emphasize human-like conversational interactions at these moments but use more cost-effective elements elsewhere. Protect against prompt injections by partitioning sensitive data so it’s only accessible by secure systems. We know LLMs aren’t great at math anyway, so free them up for creative collaboration instead of managing boring billing details.
                        GENERATIONS ARE PREDICTIONS
                            In my previous Smashing article, I explained the concept of algorithm-friendly interfaces. They view every interaction as an opportunity to improve understanding through bidirectional feedback. They provide system feedback to users while reporting performance feedback to the system. Their success is a function of maximizing data collection touchpoints to optimize predictions. Accuracy gains in predictive output tend to result in better user retention. So good data compounds in value by reinforcing itself through network effects.
                            While my previous focus was on content recommendation algorithms, could we apply this to generative AI? While the output is very different, they’re both predictive models. We can customize these predictions with specific data like the characteristics, preferences, & behavior of an individual user.
                            So, just as Spotify learns your musical taste to recommend new songs, we could theoretically personalize generative AI. Midjourney could recommend image generation parameters based on past usage or preferences. ChatGPT could invoke the right roles at the right time (hopefully with system status visibility).
                            This territory is still somewhat uncharted, so it’s unclear how algorithm-friendly conversational interfaces are. The same discoverability issues affecting their usability may also affect their ability to analyze engagement signals. An inability to separate signal from noise will weaken personalization efforts. Consider a simple interaction like tapping a “like” button; it sends a very clean signal to the backend.
                            What is the conversational equivalent of this? Inputting the word “like” doesn’t seem like as reliable a signal because it may be mentioned in a simile or mindless affectation. Based on the insights from my previous article, the value of successful personalization suggests that any regression will be acutely felt in your company’s pocketbook.
                            Perhaps a solution is using another LLM as a reasoning engine to format unstructured inputs automatically into clear engagement signals. But until their data collection efficiency is clear, designers should ask if the benefits of a conversational interface outweigh the risk of worse personalization.
                        Towards The Next Layer Of Abstraction
                            As this new paradigm shift in computing evolves, I hope this is a helpful primer for thinking about the next interface abstractions. Conversational interfaces will surely be a mainstay in the next era of AI-first design. Adding voice capabilities will allow computers to augment our abilities without arching our spines through unhealthy amounts of screen time. Yet conversation alone won’t suffice, as we also must design for needs that words cannot describe.
                            So, if no interface is a panacea, let’s avoid simplistic evolutionary tales & instead aspire towards the principles of great experiences. We want an interface that is integrated, contextual, & multimodal. It knows sometimes we can only describe our intent with gestures or diagrams. It respects when we’re too busy for a conversation but need to ask a quick question. When we do want to chat, it can see what we see, so we aren’t burdened with writing lengthy descriptions. When words fail us, it still gets the gist.
                        AVOIDING TUNNEL VISIONS OF THE FUTURE
                            This moment reminds me of a cautionary tale from the days of mobile-first design. A couple of years after the iPhone’s debut, touchscreens became a popular motif in collective visions of the future. But Bret Victor, the revered Human-Interface Inventor (his title at Apple), saw touchscreens more as a tunnel vision of the future.
                            In his brief rant on peripheral possibilities, he remarks how they ironically ignore touch altogether. Most of the interactions mainly engage our sense of sight instead of the rich capabilities our hands have for haptic feedback. How can we ensure that AI-first design amplifies all our capabilities?
                            “A tool addresses human needs by amplifying human capabilities.” — Bret Victor in “A Brief Rant on the Future of Interaction Design”
                            I wish I could leave you with a clever-sounding formula for when to use conversational interfaces. Perhaps some observable law stating that the mathematical relationship expressed by D∝1/G elucidates that ‘D’, representing describability, exhibits an inverse correlation with ‘G’, denoting graphical utility — therefore, as the complexity it takes to describe something increases, a conversational interface’s usability diminishes. While this observation may be true, it’s not very useful.
                            Honestly, my uncertainty at this moment humbles me too much to prognosticate on new design principles. What I can do instead is take a lesson from the recently departed Charlie Munger & invert the problem.
                        DESIGNING BACKWARDS
                            If we try to design the next abstraction layer looking forward, we seem to end up with something like a chatbot. We now know why this is an incomplete solution on its own. What if we look at the problem backward to identify the undesirable outcomes that we want to avoid? Avoiding stupidity is easier than seeking brilliance, after all.
                            An obvious mistake to steer clear of is forcing users to engage in conversations without considering time constraints. When the time is right to chat, it should be in a manner that doesn’t replace existing usability problems with equally frustrating new ones. For basic tasks of equivalent importance to delivering pizza, we should find practical solutions not of equivalent extravagance to driving a Lamborghini. Furthermore, we ought not to impose prompt engineering expertise as a requirement for non-expert users. Lastly, as systems become more human-like, they should not inherit our gullibility, lest our efforts inadvertently optimize for exponentially easier access to our private data.
                            A more intelligent interface won’t make those stupid mistakes.

                    Case Study Option 2:
                    - cardHeader: Using Friction As A Feature In Machine Learning Algorithms
                    - cardDescription: In this article for Smashing Magazine, I discuss how friction often has a negative connotation in user experience design, but it actually has many benefits. Its best-known use case is mitigating unintended consequences in high-risk scenarios, yet it has a new place in the age of artificial intelligence.
                    - cardURL: https://www.smashingmagazine.com/2023/08/friction-feature-machine-learning-algorithms/ 
                    - Content: 
                        This article was published in Smashing Magazine.
                        A common assumption in user experience design is less friction makes apps more delightful. But in practice, the happy path isn’t always the smoothest. The term “friction” in the digital sense usually refers to anything that makes experiences cumbersome. It’s an analogy to the physical resistance that occurs when objects interact. Digital friction comes in many forms, from frustrating flows to confusing copy. But plenty of scenarios actually benefit with a bit of resistance. Its killer feature is mitigating unintended consequences, such as an accidental Alexa shopping spree.
                        You’ve likely already encountered intentional friction many times. Most apps leverage it for destructive actions, account security, and error handling, as recommended by experts from Norman Nielsen Group to the magazine you’re currently reading.
                        Yet friction has found a new calling in the age of artificial intelligence. When implemented correctly, it can improve the efficiency of AI systems such as machine learning algorithms. These algorithms are often used to personalize experiences through predictive recommendations. Some applications incorporating these algorithms realize that adding a bit of friction to their interface can turn each user interaction into an opportunity to improve algorithmic quality.
                        While less friction makes an app smoother, a bit more may make it even smarter.
                        Friction As A Feature
                            Before venturing down the AI rabbit hole, let’s explore some simple examples showcasing the basic benefits of friction in UX. These are a helpful foundation to build off as we ascend into more complex applications for machine learning algorithms. Regardless of your familiarity, this will ground the following lessons in first principles.
                        PREVENTING UNINTENDED CONSEQUENCES
                            A common use for friction is error prevention, the fifth entry in Jakob Nielsen’s list of usability heuristics. In scenarios with the potential for high-cost errors, such as irreversible deletion, apps often request confirmation before executing requests. Confirmations often display in a modal, locking the rest of the screen to increase focus on copy explaining an action’s implications. This extra step provides some extra time to consider these ramifications.
                            “By forcing us to slow down and think at this exact moment, we’re kept from making potentially disastrous decisions by accident.” — Archana Madhavan in Amplitude’s “Onboarding With The IKEA Effect: How To Use UX Friction To Build Retention”
                            Sometimes more resistance is present when the consequences can be catastrophic. For instance, a confirmation may involve cognitive work such as typing “DELETE” to submit a deletion request. This level of resistance makes sense when considering the humbling fact of life from Steve Krug’s classic UX book Don’t Make Me Think, which states, “We don’t read pages. We scan them.” This makes it easy to imagine how a streamlined design can make it too easy to overlook the consequences of a click.
                            While these tactics may look comically cumbersome, they mitigate devastating downsides. This use of friction is like a train’s brakes screeching to a halt right in time to avoid a collision — everyone breathes a sigh of relief, crisis averted. This also outlines the basic framework for understanding when to add friction. It boils down to a cost-benefit analysis: do the rewards of streamlining outweigh the risk? If not, slow it down. Now let’s move on from a black & white example to venture into a grayer area.
                        NUDGING TOWARD HEALTHY BEHAVIOR
                            Some problems aren’t classifiable as errors but still aren’t in anyone’s best interest. Trying to solve them becomes wicked because there is no right or wrong solution. Yet that doesn’t make failing to address them any less of an existential risk. Consider social media’s medley of knee-jerk, tribalistic behavior. It has led many to question the value of these apps altogether, which isn’t good for business, or society at large. In an attempt to encourage more thoughtful discourse, these platforms turn to friction.
                            Twitter explored adding an extra step that asks people to read articles before retweeting them. This nudge aims to craft a more trustworthy experience for everyone by slowing the spread of misinformation. According to their reporting, people shown the prompt opened articles 40% more often, and some decided not to retweet it after all. They built on this success by showing a warning before users post messages which include harmful language.
                            Instagram also implemented a similar feature in its fight against online bullying. Adam Mosseri, the Head of Instagram, published a blog post stating that this “intervention gives people a chance to reflect.” Although specific data isn’t provided, they suggest it had promising results in cultivating a more humane experience for their communities.
                            These examples show how faster is not always better. Sometimes we need restraint from saying things we don’t mean or sharing things that we don’t understand. Friction helps algorithms in a similar manner. Sometimes they also need more information about us so they don’t recommend things we won’t appreciate.
                        UNDERSTANDING PREFERENCES & OBJECTIVES
                            Let’s shift focus to AI with a simple example of how friction plays a role in machine learning algorithms. You’ve probably signed up for an app that begins by asking you a bunch of questions about your interests. Behind the scenes, an algorithm uses these answers to personalize your experience. These onboarding flows have become so common over the past decade that you may have forgotten a time before apps were smart enough to get to know you.
                            You may have never even questioned why you must go through a preference capture flow before getting to explore content. The value is obvious because no one wants the quickest path to something irrelevant. Many apps are simply in the business of making relevant connections, and these personalization tactics have been one of the best ways to do so. A McKinsey report illuminates this further by reporting that “35 percent of what consumers purchase on Amazon and 75 percent of what they watch on Netflix come from product recommendations based on such algorithms.”
                            “The top two reasons that customers churn are 1) they don’t understand your product, and 2) they don’t obtain any value from it. Customer onboarding can solve both of these issues.” — Christina Perricone in HubSpot’s “The Ultimate Guide to Customer Onboarding”
                            Perhaps these onboarding flows are so familiar that they don’t feel like friction. They may seem like necessary steps to unlock an app’s value. However, that perspective quickly changes for anyone designing one of these flows. The inherent tension lies in attempting to balance the diametrically opposite needs of two parties. On the one hand, an algorithm provides better output relative to its input (although asymptotes exist). Success is a function of maximizing data collection touchpoints, but this tends to result in more steps with more complex questions.
                            In short, the quicker an app makes a recommendation, the more likely it will be wrong. On the other hand, an extremely long onboarding flow is unlikely to make an amazing first impression on new users. I had the pleasure of walking this tightrope when designing the onboarding flow at Headliner. Each new step we added always felt like it would be the straw that broke the camel’s back. We nervously monitored our activation reports for signs we went too far but surprisingly saw no meaningful dropoff. Yet, even a slight decrease would easily be worth the improved retention that personalization yielded.
                            The Product Design Manager at Stitch Fix, Deanna Alcorn, documented their process of working through this. The tension is clearly illustrated when she asks the question, “How do we get customers to evaluate as many images as possible while keeping it fun and fast?”. While their case study is a great reference, the right solution will be different for every app. Your onboarding flow should follow the needs of your algorithm while balancing the needs of your users.
                            With that said, there is one app that is legendary for its rapid personalization, and surprisingly, it doesn’t have any onboarding flow at all.
                        Giving An Algorithm Glasses
                            TikTok’s personalization is so good that the New York Times compares it to mind reading. But after signing up for their service, you can just start browsing! In stark contrast, Instagram has multiple onboarding steps without the same algorithmic reputation. How can TikTok have such an advantage if it doesn’t even ask you what you want to see?
                            This is thanks to some clever interface innovations. TikTok’s design turns user engagement into clear signals they use to tweak their algorithms. Content recommendation quality is a direct function of this, which some refer to as an algorithm’s vision.
                        ENGAGEMENT SIGNALS
                            Every interaction is an opportunity to improve understanding through bidirectional feedback. An interface should provide system feedback to the user engaging with it while also reporting to the system how performance meets user expectations. Everything from button taps to the absence of action can become a signal. Interfaces that successfully incorporate this are referred to as algorithm-friendly.
                            A study by Apple’s Machine Learning Research Department details their success in leveraging engagement signals, which they believe “provide strong indications of a user’s true intent,” to efficiently train a machine learning model through a process called Reinforcement Learning from Human Feedback. Their results documented “significant accuracy gains in a production deep learning system,” meaning that an interface designed well enough to analyze naturally occurring user behavior is all that is needed to create personalization that feels like mind reading.
                            Instagram actually employs this strategy as well, although its approach is a bit less cohesive since they seem to be in a perpetual state of transition.
                        TIKTOKIFICATION
                            But what exactly makes an interface algorithm-friendly? In TikTok’s case, it was the design decision to only show one video at a time. That’s right, friction! By decreasing the information density in the viewport at any given time, they increased their understanding of a user’s focus. This localizes interactions (or lack thereof) to specific content as quality measures.
                            Gustav Söderström, the Co-President, CPO & CTO at Spotify has referred to this approach as “giving the algorithm glasses.” Compare this to the medley of distractions in other feeds, and it’s easy to imagine which one is better at collecting data.
                            As we return to my aforementioned framework for evaluating when to add friction, we can understand how it makes sense in this scenario. While each interaction may take slightly longer, relevant content can be found quicker. The trade-off makes sense since relevance sits atop a user’s hierarchy of needs.
                            Additionally, if you were to measure friction over a longer time horizon, you likely would find an experience with better personalization feels more frictionless. This is because the efficiency in helping users find what they’re looking for would consistently compound (although, again, asymptotes exist). So each subsequent visit theoretically requires less work on the user’s part, which makes the alternate approach look like the cumbersome one.
                            “The secret of why some of these products are so good at recommendations is not actually that they have better algorithms. It’s the same algorithms with a more efficient user interface.” — Gustav Söderström in The Verge’s “Why Spotify wants to look like TikTok”
                            While TikTok popularized this interface, anybody who was single in the last decade may notice a similarity to dating apps. Using directional gestures as engagement signals dates back to the swipeable card paradigm Tinder introduced in 2012. They, too, limited the viewport to one result at a time and used actions to inform subsequent recommendations. But TikTok took it mainstream since not everyone needs a dating app, and those who do will churn once they’ve met someone.
                            The results of using this paradigm in everyday entertainment led many platforms to copy it in hopes of the same algorithmic gains. The latest to embark on this journey is Spotify, much to the chagrin of their users. In fact, this decision even landed it on Mashable’s list of worst app updates in 2023. But Söderström says they don’t have a choice, and he believes in the long run, the signal clarity will make up for any interim backlash because of how much quicker it can learn user preferences. Critics fail to realize how important these changes are for Spotify’s future.
                        MAKING LEMONADE
                            The reason this approach is so powerful is due to the compounding nature of good data. Optimizing signals for any individual user creates a data network effect that benefits everyone else. It even turns negatives into positives! An individual bad experience can mitigate others from encountering the same, making the system antifragile.
                            This approach dates back to 2003 with the introduction of Amazon’s item-to-item collaborative filtering. You may know it as “customers who viewed this also viewed this.”
                            This type of filtering produces high-quality recommendations with limited user data. It does so by building relationships between items to proxy user preferences. With only two to three data points, an algorithm can draw connections across the entire dataset. It effectively piggybacks off previous patterns that are similar enough.
                            This means an app like TikTok only needs a few swipes before it can make high-probability assumptions about your preferences. That’s why friction is so useful in algorithm-friendly interfaces. If the initial interactions send clean signals, then an algorithm can graph a user’s interests almost immediately.
                        Friction In The Future
                            We began in the past by reviewing how friction found its way into UX toolkits through error prevention and healthy nudges. Then we moved on to its ability to help algorithms learn user preferences and objectives. While explicit onboarding flows are still in vogue, TikTok is popularizing an interface that makes them unnecessary by using implicit engagement signals leading to significant algorithmic gains. Yet the machine learning age is just beginning, and friction is only accelerating its evolution.
                        INVERTING THE PARETO PRINCIPLE
                            We’ve focused on algorithms that recommend content, but more diverse uses of personalization may emerge due to the newfound capabilities of Large Language Models. These models unlock the ability to manipulate unstructured data at scale. This allows engagement patterns of greater complexity to be analyzed and productized. The result is algorithms can recommend much more than media and metadata.
                            Perhaps they can craft completely personalized feature sets based on our preferences and objectives. Imagine selecting effects in Photoshop and seeing suggestions such as “Creators who used this effect also used this one.” These capabilities could increase the usage of buried features that only power users tend to find.
                            Microsoft is exploring this by adding Copilot to its products. They claim the “average person uses less than 10% of what PowerPoint can do,” but AI will unlock all that latent value.
                            Using LLMs to create feature recommendation engines is a fascinating idea. It would allow developers to stop relying on the Pareto Principle for prioritization. Especially because Joel Spolsky claims the 80⁄20 rule is actually a myth.
                            “A lot of software developers are seduced by the old “80/20” rule. It seems to make a lot of sense: 80% of the people use 20% of the features… Unfortunately, it’s never the same 20%. Everybody uses a different set of features.” — Joel Spolsky in “Strategy Letter IV: Bloatware and the 80/20 Myth”
                            It would be nice if irreducible simplicity in interface design were only a power law away, but feature creep is hard to combat when different people find value in different options. It’s unrealistic to believe that there is some golden 20% of features driving 80% of value. If there was, then why isn’t the Pareto Principle ever applied to content?
                            I can’t imagine a team at YouTube suggesting that removing 80% of videos would improve the service. Instead, it’s viewed as a routing problem: find the right piece of content for the right person. If machine learning algorithms can recommend features, I hope the value of friction goes without saying at this point. The efficiency gains unlocked by algorithm-friendly interfaces absolutely apply.
                        HALLUCINATIONS OR CREATIONS
                            The recent inflection point in the capability of LLMs unlocks an entirely new computing paradigm. The legendary UX researcher Jakob Nielsen believes it introduces the first new UI paradigm in 60 years, which he calls Intent-Based Outcome Specification. Instead of telling computers what to do, we now explain an outcome so they can determine how to achieve it.
                            Using machine learning algorithms to recommend features is one example. Another fairly new example that you’re likely familiar with is chatbots like ChatGPT. Hundreds of millions of people already use it, which is a testament to how out of this world the experience is. Yet therein lies a problem: sometimes its responses literally aren’t grounded in reality because it has a tendency to make them up! This isn’t obvious to those unfamiliar with the technology’s inner workings since there aren’t many safeguards. As a result, some people become dangerously overreliant on its unverified output.
                            In one case, a lawyer based legal arguments on research from ChatGPT only to find out in court that multiple cited sources turned out to be completely nonexistent. The lawyer’s defense was that he was “unaware of the possibility that its content could be false.” Examples like this reinforce the importance of friction in preventing unintended consequences. While ChatGPT’s empty state mentions its limitations, they obviously aren’t stated explicitly enough for everyone.
                            Extra steps and prompts, such as those mentioned earlier, could better educate users about what is referred to as a “hallucination.” It’s a phenomenon of chatbots confidently outputting responses that don’t align with their training data. Similar to telling a lie when you don’t have a correct answer, although that characterization overly anthropomorphizes the software.
                            Yet some see hallucinations as more of a feature than a bug. Marc Andreessen, the co-founder of Netscape, states during an interview that “another term for hallucination is just simply creativity.” He views it as a significant evolution from the hyperliteral systems of the past because they can now brainstorm and improvise.
                            The problem is that chatbot interfaces tend to be simplistic by attempting to be one size fits all. More controls or modes would educate users about available output types so they can specify which they expect. Sometimes we may want an imaginative response from a creative partner. Other times we want the hyper-accuracy of a deterministic calculator, such as ChatGPT’s Wolfram plugin.
                            Perhaps a creativity slider or persona selector similar to Maggie Appleton’s exploration will better align the system to user needs. However it’s implemented, a bit of friction can maximize benefits while minimizing risks.
                        Finding Your Friction
                            We’ve covered using friction for simple error prevention to complex algorithm optimizations. Let’s end with a few tips that make implementing it as smooth as possible.
                        PEAK-END RULE
                            When adding resistance to an experience, the Peak-End Rule is a useful psychological heuristic to leverage. It’s rooted in studies by Daniel Kahneman & Amos Tversky, where they found that perception of painful experiences doesn’t tend to correlate with duration. It’s the peak & end of the experience that subjects recall.
                            In practice, experts suggest that delight is a function of positive emotional peaks and rewarding emotional payoffs. Optimizing for the peak & end provides room to shift focus from time spent and steps taken as performance indicators; long and complex experiences can still be delightful if designed correctly.
                        MAPS AREN’T TERRITORIES
                            People experience friction emotionally, but developers see it as a value on a chart. In the same way that a map is not a territory, this ratio is only an approximation of the actual experience. It’s something to consider when evaluating any strategies for adding or removing friction. Since applications are complex ecosystems, any measurements should consider a holistic view. Every step has second-order effects, which makes one-dimensional measurements prone to blind spots.
                            For example, when a wrong file is deleted, the data can’t report people cursing at their computer screen. Nor is it likely to include the context of them opening a new file just to recreate their old file from scratch. The same subjectivity applies to all instances of friction. For instance, are your reports equipped to measure the trade-off of an action that takes longer but results in better data collection? It might increase algorithmic efficiency, which compounds across a neural network.
                            As we’ve discussed, better recommendations tend to yield better retention, which tends to yield more revenue if a business model aligns with usage. Myopic measurements will miss these types of gains, so make sure to analyze friction in a way that really matters.
                        KEEP PUSHING
                            As software is eating the world, AI is eating software. If it’s a paradigm shift as big as social, mobile, or even the web, then applications must adapt or die. If you want to remain competitive in the machine learning age, then don’t fear friction.

                    
                    Case Study Option 3: 
                    - cardHeader: Designing algorithm-friendly interfaces
                    - cardDescription: In this article for UX Collective, I discuss how designers must craft interfaces to empower artificially intelligent experiences as they become commonplace. This article explores how a user interface can become a great tool to separate signal from noise to help algorithms better understand user intent, resulting in greater personalization quality.
                    - cardURL: https://uxdesign.cc/designing-algorithm-friendly-interfaces-84da3ed076a9
                    - Content: 
                        This article was initially published in UX Collective.
                        As artificially intelligent experiences become commonplace, designers must craft interfaces to empower them.
                        A designer must be intricately familiar with her materials. In the past this meant understanding the nuanced properties of woods, metals, printing presses, & eventually pixels. Today’s digital designers must work with a much more intangible material: an algorithm.
                        They were once comparatively simple sets of rules an application followed to accomplish tasks, such as displaying posts by people you follow. Now they’ve evolved with artificial intelligence into infinitely complex fractal processes often beyond human comprehension. They power most of our daily experiences, but the majority of design literature on this new norm focuses on if these robots will replace us. Instead, let’s discuss how designers can better assist engineering counterparts by reframing design decisions to amplify algorithmic performance.
                        User-centered design is no longer enough, the interfaces of the future must be easy for people to use & easy for algorithms to analyze.
                        The needs of algorithms
                            Algorithms are responsible for most content surfaced in our digital products: posts populating social feeds, shopping suggestions in digital carts, & phrase recommendations in email drafts. They succeed by showing us what we want, when we want — just like a helpful assistant or store clerk. Self-proclaimed ‘humanist technologist’ John Maeda explains their goal in his latest book by likening it to the Japanese custom of ‘omotenashi’: anticipating what the customer wants without asking.
                            However, algorithms are not a solo act. They must be harmoniously paired with intelligently crafted interfaces in order to succeed.
                        Purpose & process
                            Most algorithms focus on automatically detecting patterns in data & subsequently making relevant recommendations. This process is achieved by pairing a specific dataset with analysis dimensions to create what is referred to as a model. It’s then trained by continuously feeding in more data over time, resulting in theoretical improvements. The output is often used to personalize a product: customizing each user’s experience.
                            “More personalization in the user experience usually means more relevance for users, which leads to better conversion rates.” Fabricio Teixeira, UX Collective
                            This explains why data is the new gold. But the originality of most companies’ value propositions means there is rarely a robust public dataset readily available to efficiently train their models.
                            Feedback loops & signals
                            To train a novel model, many companies must act like ouroboros by turning their product into a data collection mechanism that simultaneously uses the results to improve itself. Within this feedback loop, relevant user interactions are tracked as data signals: anything from button taps, gestures, or even an absence of action altogether.
                            “The fact that you linger on a particular image longer than the rest can imply you have an interest in it. Or the fact that you have started typing something and then turned around and left the field incomplete indicates hesitation.” John Maeda
                            A well-designed interaction is intuitive but also separates signal from noise.
                        Algorithm-friendly design
                            The term ‘algorithm-friendly design’ was dubbed by Eugene Wei, a product leader formerly at Amazon, Hulu, & Oculus, to describe interfaces that efficiently help train a model:
                            “If the algorithm is going to be one of the key functions of your app, how do you design an app that allows the algorithm to see what it needs to see?”
                            This explains the myriad interactions that exist solely to gauge user sentiment, such as Reddit’s downvoting or Tinder’s card swiping — they’re useless in isolation but very valuable to algorithms.
                        TikTok’s innovative interface
                            As artificial intelligence undergoes breakneck advances in accordance with Huang’s law, more elegant design solutions are emerging to evolve the paradigm of providing algorithmic visibility. Today’s most mythical algorithm, TikTok’s, utilized its interface to quickly unlock troves of user data for highly competitive content recommendations. Counterintuitively, it did so by employing one of design’s deadly sins: adding friction.
                            The design decision to show only one fullscreen video at a time cleanly localizes all signals on how content is received. Compare this to the medley of distractions around content in Instagram’s feed & it’s easy to see the difference in ability to collect good data — which explains Instagram Reels.
                            In most feeds we can swipe with varying degrees of intensity, allowing us to instantaneously skip past tons of content without telling the algorithm why. This convolutes the analysis:
                            - Was this content scrolled past too quickly to register?
                            - Was the preview only partially in frame?
                            - Was there distracting content above or below?
                            Constraining the scroll interaction makes it a highly effective interpreter of user sentiment. The real beauty of this solution is its invisible downvote button: a swipe can be cleanly counted as a negative signal when paired with an absence of positive engagement.
                        Friction removes friction
                            Although this design decision adds friction initially, over time the opposite becomes true. Improved personalization eventually reduces the amount of recurring actions required, thanks to the compounding interest of good data. In this light the traditional approach actually seems much more cumbersome, as Wei exemplifies with Twitter:
                            “If the algorithm were smarter about what interested you, it should take care of muting topics or blocking people on your behalf, without you having to do that work yourself.”
                            A well-designed onboarding flow could easily minimize the perception of upfront friction until the personalization threshold kicks in.
                            The algorithmic observer effect
                            As documentaries like The Social Dilemma trend, many are increasingly suspicious of how apps misuse data & manipulate behavior. Awareness of algorithmic gaze is altering user engagement: some people may hesitate to click certain buttons in fear their signals will be misused, while others may take superfluous actions to confuse nosy algorithms.
                            If users do not trust a product, then a product cannot trust its data.
                        How to introduce an algorithm
                            When Cliff Kuang, the former Director of Product Innovation at Fast Company, interviewed the Microsoft team responsible for building AI into PowerPoint, they shared a key realization:
                            “Unless the human felt some kind of connection to the machine, they’d never give it a chance to work well after it made even one mistake.”
                            This insight came from comparing fully autonomous virtual assistants with others that took initial direction before providing independent suggestions. It turns out that users trust algorithmic experiences they help train, which makes a lot of sense because our evaluation is often subjective & initial suggestions have less user preference to base off.
                            Letting people steer initial decisions satisfies our emotional needs while giving a model enough time to train itself.
                        Transparency as a strategy
                            On the a16z Podcast, Wei highlights TikTok’s decision to make their algorithmic weighting public by adding view counts to hashtags & utilizing content challenges. This incentivizes creators, hoping to achieve outsized views, to align efforts with what the service is amplifying. This behavior was once called gaming an algorithm, but the success of this strategy should reverse that negative connotation. If users willingly fill gaps in datasets when their goals are aligned, we should call that collaboration.
                            Twitter’s CEO is already considering something similar:
                            “Enabling people to choose algorithms created by third parties to rank and filter their content is an incredibly energizing idea that’s in reach.” Jack Dorsey
                            If black box algorithms give us filter bubbles (see Blue Feed, Red Feed) perhaps transparent algorithms can burst them.
                            In conclusion, algorithms still need humans
                            Spotify’s Chief R&D Officer, Gustav Söderström, spoke with Lex Fridman about setting user expectations for song recommendations. When people are in discovery mode (feeling adventurous enough for questionable suggestions) Spotify leads with machine learning. But in contexts with little margin for error, they still rely on human curators because they outperform algorithms:
                            “A human is incredibly smart compared to our algorithms. They can take culture into account & so forth. The problem is that they can’t make 200 million decisions per hour for every user that logs in.”
                            To scale these efforts, they’ve developed a symbiotic relationship called ‘algotorial’ where an algorithm follows a human’s lead—sound familiar? It’s a nice reminder of humanity’s indispensability, as we designers realize that helping algorithms succeed is now part of our job — that is, until they come to take it away from us ;)

                    Case Study Option 4: 
                    - cardHeader: Product, Explained S2E2 - Maximillian Piras, Explained
                    - cardDescription: In this podcast, Jeff Leff & Mike Alcazarin interview me about my role at Headliner where I lead cross-platform UI & UX. Headliner is a video creation tool designed for audio creators to make audio easily shareable across the web by automatically transforming audio clips, like this, into engaging videos. We also talk about the importance of side projects, user research, & the latest podcasting trends.
                    - cardURL: https://play.headliner.app/podcast/1de99e587cbc4afb87a2ae11cad50688/episode/https%3A%2F%2Fpinecast.com%2Fguid%2F25ad7cbb-cfcf-4c8f-b2a9-e9513aca0989
                    - Content: 
                        This is a podcast.
                        Product explain is a show where we talk about products and the company's history
                        Maximilian Piras: Essentially, we operate with, uh, two beliefs that drive our mission. The first is that we don't believe that the web, or the Internet in general, is optimized for audio. Of course, there's destinations that do audio well, where you go and listen to a catalog of something. But if you look at the way people browse the web, the patterns are all really focused on either text or imagery or video.
                        Jeff Lee: Hey, guys. Welcome to product explain, a show where we talk about products and the company's history and strategy behind them. This season, we're inviting folks from in the field, uh, onto the show to dive deeper into the products they love and the history behind them. I'm your first host, Jeff Lee.
                        Mike Alcazarin: And I'm your co host, Mike Alcazarin. Today we're joined by Maximilian Piras, a product designer with headliner video. Headliner is a video creation tool designed for audio creators, making audio easily shareable across the web by automatically transforming audio clips just like this into engaging videos. At headliner, Max leads cross platform UI and Ux. Prior to headline, Max worked in various product design roles at, uh, companies like Simple Habit, eight tracks, and Visualmax. Max, welcome to product explained.
                        Maximilian Piras: Yeah, thank you so much for having me. It's a pleasure to be here. Jeff and Mike. Looking forward to it.
                        Mike Alcazarin: Yeah, absolutely. I know I was telling you before the show, but I'm so jazzed to be talking to someone from headliner, because we use headliner for every single video. I think this is episode 113 114. I'm not sure when we'll release this one. And we've used headliner to publish all of our socials, so it's really cool to get a sneak peek behind the, uh, behind the curtain, for lack of a better word.
                        Max's startup started as a street art project that eventually evolved into entrepreneurship
                        Max, I was looking at your background, and it's really cool journey just on how you landed in product design as a career, and you have a lot of interesting steps and stops along the way. I saw also that one of these stops included you built a niche streetwear brand that ended up getting sold at the new museum in New York. Uh, tell us about the lost cat story.
                        Maximilian Piras: Yeah, absolutely. That's a fun one to start on. Very strange project, very different time in my life, but it was a lot of fun, learned a lot. It started as a personal project that eventually evolved into my first stab at entrepreneurship. It was just an art project at first that I would do on weekends to escape my day job of designing apps. And it was just kind of like a fun thing to get out of the mode of being on a computer and think about things in a different light. It was actually, uh, a street art project at first. I was at the time when street art was having its moment, Shepherd Fairy was blowing up. All those types of artists were just really in vogue, and I was just really excited about the concept of getting art onto the streets in front of people in a super grassroots way without having to deal with a bunch of bureaucracy and all that. And so I just wanted to get involved and make my own project. And I, uh, actually had studied graphic design in school and had been an illustrator my whole life. So I got to put those skills to use as a kind of nice way to get out of the app world and started creating some posters that were hung up around the city. No, uh, comment on how they got hung up. They were up on the wall, and, uh, they were depicting this cartoon cat. And up top, it had the headline that said lost cat. And upon further inspection, you find out that the cat was not actually physically lost, but it was spiritually searching for itself, and so it was mentally lost. And that was just kind of by the time I was super into philosophy and just thought it was kind of a fun way to inject some kind of deeper thinking into people's day by having them stumble across this poster that would have. It had sayings on it. Like, uh, the first one was said, if found, then consider that we're all lost in some sense. And I just thought it was a fun way to kind of get people out of their daily routine and get them to think about things in a different light. And so they were hung up around the city, and I would just kind of watch to see if anybody interacted with them, and people would stop and think about them, and so they would take photos, et cetera. And I just thought it was actually even funner to kind of have the view of people interacting with the art. So I ended up documenting, like, uh, voyeuristically documenting people stopping in front of the posters. 
                        And then those became a photo series that I started posting online. And, uh, it just got a really good response, so I just kind of kept rolling with it and tried to see where I could take it. And eventually it ended up finding its way into shirts, and I started selling them around the city. I brought them first to a skate shop in New York called labor, and that was kind of my MvP. So I was like, well, if people like the posters, maybe they'll like the shirts. Yeah. And the owner of labor was excited about it, so he let me, he put them in there on consignment and they just kind of. They sold out. And I just kind of kept building off that momentum. And eventually, uh, I got them into the new museum, which was a really big milestone, and at this point, turned into an actual company that I was running with two friends of mine who are George Lois, and Jeremy Nakamura. And we were just running out of my apartment. But, um, eventually I came to the conclusion that although we kind of been finding product market fit, I did just start to feel like, um, since, uh, I'm working in tech and kind of leveling up my product knowledge there, I started to realize how much slower clothing is in terms of innovation than something like software. And so the project lost cat that was supposed to be fun, was now becoming actually more stressful than my normal job. I was dealing with logistics, manufacturing.
                        I'm a huge promoter of side projects. Everyone wants to. Sometimes those might shift over time
                        Jeff Lee: Um, I want to dive into a follow up question. So Mike and I are kind of, like, in a lot of the same veins, like, serial side gig people. We like to explore other things outside of work, which it sounds like it's something that you did. Um, and I like that you talked a little bit about how it went from kind of this fun, creative outlet to maybe becoming bigger than you wanted it to be, and you realize you needed to kind of step away. Talk. I'd love to hear about your thoughts on, like, how do you find that balance? Like, are there other things that you've worked on where you started to, like, put in some more of your creative energy and it got you somewhere else, or do you find that these are just intended to be kind of side things, that they'll run its course and then you move on to the next thing?
                        Maximilian Piras: Um, I'm, um, a huge promoter of side projects. Like, I've always got a side project going, and just. Cause I'm kind of a workaholic, so it's at some level, I'm also trying to chill out a little bit.
                        Maximilian Piras: But it's just kind of addictive to get something going and see it. Hopefully it starts taking off. But I think, um, it's a great outlet to just explore different things that you're not able to do during the week, but having, uh, some time to reflect and say, is this actually what I want to do? I think keeping those goals in mind is super useful. And in this case, I just said, well, I really have no interest in working in fashion or creating a clothing brand. Although it sounded cool at first, when you see behind the scenes of what it's actually entails, I think it was kind of like a sober moment to say, okay, I think I've learned enough at this point, and it's time to use this time to, it's a kind of opportunity cost. So I said, okay, I could keep running, like, kind of a little niche streetwear brand or whatever it's shaping up to be, or I could use that time elsewhere. And so I ended up just jumping into animation after that, and which was another kind of side project that took its course. And I also said, okay, well, I've learned animation. This is a lot of fun. I started actually getting some freelance jobs that I would do on the weekends. And I realized as well, like, animation is not what I want to do full time. It's so much work, like kind of a, uh, much less roi than you get in software. And so again, I went back to saying, okay, time to close the lid on this one and spend that time elsewhere. But 100%, I think side projects are, like, a really good resource that people should totally take advantage of and 100% promote them.
                        Jeff Lee: Yeah, sometimes I found the same thing where, uh, I put too many irons in the fire. And then I realized that, like, none of them are really. Somebody gave me the analogy once of like, uh, kicking 100 soccer balls. Like, you're trying to progress all them forward slightly, and ultimately you're like, I need to do less in order to progress them a little bit further. And I need to figure out which ones are providing me the most joy, or sometimes it's monetary value or whatever you're optimizing for. So it's interesting to kind of hear other folks take on what happens when you're exploring a bunch of things, because I think it's really hard. Everyone wants to. If you're kind of like a serial entrepreneur, you're trying to do everything and be the best at everything, but in reality, you have to kind of pick the one or two lanes that you want to be really, really good at. Sometimes those might shift over time. It might not be forever. That you're doing this one thing and kind of kicking ass at it.
                        Um, and I guess like following up on your long line of side projects, I heard that you spent time as a, ah, movie poster designer, so could you tell us a little bit about that? I think that's also, it sounds like kind of similar to the Lost Cat poster idea, which kind of evolved into this art piece and art experience. But tell us about movie poster design specifically.
                        Maximilian Piras: Yeah, absolutely. In the same vein of, you know, during my twenties, just exploring a lot of different avenues. And when I was growing up, I was in love with movies. I still am, but I wanted to be a director when I was a kid and I had my little camera that I was filming little skits with my friends and I eventually skewed into visual art and design and just kind of fell in love with that route. But then, uh, m getting towards my mid twenties, I had started working in tech and was working at an agency, which all they did was banner ads and microsites. And that was kind of my first view of what it meant to be professional in tech. I'd been building websites my whole life, so I knew that I loved building for the web, but just actually work in that context. I kind of had a not super fun intro to it and so I was starting to search for maybe other ways to spend my day and I had this opportunity to start working at, uh, an agency that designed movie posters. And since I came from a love of movies and like, you know, a lot of artists like Saul Bass, who I really loved all the posters they designed, I thought this would be an amazing intersection of my interests. So I tried it out and I quickly found out that it was actually even less creative than doing banner ads and like the most formulaic just churn out the same thing. Factory all my time was pretty much like airbrushing movie stars faces to get their wrinkles out. And I uh, just kind of realize what the whole industry model over there sets it up in a way that there's actually not that much room for creativity because the studio will send out an RFP request for proposal to all these agencies and they're all kind of fighting for the bid and they have very short timelines, so they're just really.
                        Maximilian Piras: Incentivized to do what they know works and they don't have time to like add in psychographics or market analysis and such, so they just kind of churn out something that feels very familiar to everything else. And their goal is to not raise eyebrows. It has to look similar enough, but be a little different. And so, yeah, that ended up uh, being the complete opposite of what I thought it would be. And I started to realize all the posters that I really liked, like Mondo or, you know, the ones that are more creative, like the Saul bass ones, those are probably for smaller releases. You know, they're probably for indie movies that have a very small distribution. And so to be successful in industry as well, you're kind of working in that agency world. And I just kind of came to the conclusion that the web was actually a lot more fun to work on than this. And I hadn't found startups yet, but I was lucky enough to get, lucky enough to get an offer at Ahrefax right after that, which was the first startup I worked at and just totally fell in love with it and was really excited to get back into kind of the freedom of software again. So it was a very similar process of kind of figuring out exactly, uh, diving in to figure out what the nuts and bolts were and realizing it wasn't actually for me. So here I am back in tech.
                        Mike Alcazarin: Yeah, that's a good transition to, to, you know, to hear more about what you're doing today at headliner. And like I said, I'm um, super jazzed to take a peek under the hood because we've been using headliner for the past two years.
                        Headliner is a suite of tools designed to help podcasters extend reach
                        But before we dive into that though, tell our audience, you know, what is headliner?
                        Maximilian Piras: Yeah, for sure. That's super. It's really cool to hear the guys users of it. And this might turn into like a semi usability test. User interviews. So sorry if I start digging into how, you know, how we can improve, et cetera, but I'm always really excited to meet users of the product. Um, so yeah, headliner is a suite of tools that we created to help podcasters extend the reach of their shows. The mission is to increase the audience of any audio by increasing its discoverability across the web. So this is things like making it more searchable in search engines, helping create trailers for it. Essentially we operate with uh, two beliefs that drive our mission. The first is that we don't believe that the web, or the Internet in general, is optimized for audio. Of course there's destinations that do audio well, where you go and listen to a catalog of something. But if you look at the way people browse the web, the patterns are all really focused on either text or imagery or video. And so audio actually doesn't naturally fit into a lot of those patterns. So the work we do at headliner is really focused on figuring out how to optimize audio to be better discoverable in all those modes, like searching or browsing on social. And, uh, the second belief is that it's kind of a byproduct of that. First one is that we don't think that the majority of listeners out there even have a podcast app installed yet. So this has, um, led us to start thinking about how do we find audiences for podcasters in places that aren't currently in vogue. Like, what's the next set of listener, where the next set of listeners going to be? Because we don't think they're in a podcast app. If you look at the stats, podcast consumption is still, although it's growing, it's still so far behind video and other types of media. So, uh, yeah, these beliefs are what drive our product development, and we're just trying to create tools that help podcasters get their audio out there.
                        I wanted to comment on, the web is not built for audio. My wife is a, um, she, every movie that we watch at home has to have clothes closed captions on. And then I used to kind of poke fun at her for it, like, oh, why do you need this? But then we watch Game of Thrones with closed captions on and you have all these very unique names. Uh, I'm sure, uh, um, lord of the Rings is the same way. And you're like, oh, actually this is really helpful because it starts to kind of reinforce. I'm hearing it and seeing it and now I know all the names and what's going on and all that sort of stuff. And I really love that you kind of commented on how people explore the web. I think I stumbled on like listening and watching videos at like two or three x speed now. And it feels like a short, like a, like a superpower when you're like powering through a YouTube video that's normally 30 minutes or whatever. I'm sure people listen to our podcast in two x speed, but that's hopefully that's okay.
                        Headliner is an early stage startup still. It's been around for about five years
                        Uh, I wanted to ask overall, like, it sounds like you've kind of explored a couple different design avenues and kind of landed on tech, and so that's kind of this like mini optimization. And now you're at headliner, what makes product at, or uh, at least designed, or, you know, both at headliner unique in your perspective? Like what makes it super interesting place to work? Like, how is it different than working at maybe some of your previous stops or other places in tech that you've heard about like, tell us a bit more about that.
                        Maximilian Piras: Sure. Yeah. Uh, it's an early stage startup still. It's been around for about five or six years, I believe I joined four years ago, but it's still super small, super scrappy, and I think that's the type of company that really attracts me. I love, as you know, from my background, I kind of was all over the place. I love to just try different things, and so I love to be involved in, uh, all the different avenues as opposed to being siloed or super specialized, uh, in one avenue. So early stage startups always really attracted me, um, just to the lifestyle and kind, um, of the mode of communication they have and kind of the freedom that you have to try new things as long as you have a good reason for it. And obviously, I've always been interested in kind of building things from kind of the ground up, I think, uh, so headliner and eight tracks as well have been the two companies that the best embodied this. And uh, ever since I started on that path, I've just been constantly seeking them out. And I think design at headliner, it's, right now it's just me. So I'm the only designer team of one individual contributor. So, uh, I don't know if that keeps it interesting because I don't know how interesting I think I am. But uh, at the very least, it lets me try a bunch of things. And there's some things that I do probably not great, and there's some things that I think I do differently that could result in interesting things, because there's not any bureaucracy to really stop us from trying it. So right now we're just super biased to action and we just try to ship things and see what happens. And obviously try to ship the right things, but specifically try to ship things that can then give us feedback from our users and from our metrics in terms of telling us if we're going in the right direction. So we're still super early stage. We uh, still have under 20 people on the team, and I think that's a really fun environment. And so I've always gravitated towards them.
                        Headliner is a browser-based video editor for audio creators
                        Mike Alcazarin: So really interesting that it's been around for about six years and you've been there for the majority of life of headliner. I'm curious, how has the company evolved over the past four years? And then a, uh, second question to that that I'll append is, do you know the history of how headliner got 
                        Jeff Lee: That's exciting. Yeah. You talked a lot about initially from audiograms and how that kind of blew up. And now we see them kind of everywhere, right. Especially sometimes I'm scrolling videos and I don't want to. Maybe I'm like, in a public place and I just want to read through what they're saying, or they have bad audio and I can't hear it, and I have to kind of read it as well. It's the other, ah, use case all the way up to, um, kind of this like, AI solution, um, that you're talking about, where you're bringing up, serving up more relevant information, more relevant podcasts through disco.
                        Could you walk us through, like, other interesting, or maybe even some of your favorite short form, like, content trends right now? Like, I'm sure you guys are looking at across the board what people are doing in that space. Anything else that kind of jumps out at you. For example, right now on Instagram, I'm hearing a lot of people using those audio templates, one that comes to mind for some reason. Um, and that wraps up the 2022 season audio clip that people keep. They use it as part of their reels. Um, so I'm curious, what are some things that feel really novel and unique, um, in terms of how people are creating some of their short form content?
                        Maximilian Piras: Sure. Yeah. I mean, it's hard for me to pick a favorite because I'm always just in, like, you know, landscape analysis mode. It's always kind of a mix of there's this. This group of people who effectively think audiograms are no longer working. And again, going back to the ROI discussion, like, it's. There's really no quantifiable metric to that. So I get to. I understand why people come to that conclusion. And then there's people who are still doing and saying, well, it's still working fine. So we still see a lot of people actually, depending on your goal. I think it's, it still works well for a certain set of people. But then there's only people who are transitioning to video, and they're using, uh, you know, YouTube shorts and they're doing full video podcasts like you guys are experimenting with now. I think that's an interesting trend, but I tend to think that there will always be audio first creators, because not everybody wants to create a video. Video is just a lot more work, honestly. We, uh, started doing a video podcast for headliner, and it's just, you know, the additional anxiety of like putting on the right shirt and all that. It's just a totally different game. I think a lot of people who entered podcasting are not going to like that transition, and they'll probably focus back on audio first. Although there'd still be this segment of video creators. But I think a really interesting, uh, trend that I've seen is people using short form video to promote audio episodes.
                        Mike Alcazarin: Yeah, it's interesting that you mentioned that because one of my favorites, um, not favored but like one that's top of mind rather for me is the comedian Burt Kreischer. He has his podcast and he does like little like 32nd snippets of his interviews in video form. And then that'll be like hooked for me to go like, oh, like let's go like watch his podcast that he interviews like Taylor Tomlinson. It's like two comedians talking and shooting the shit, which is super interesting. And I uh, love what you said about like the headliner journey because as you were talking about the pain point of making videos, I was like, man, I really don't want to do that. And I was so happy when headliner started to automate all of the things that I was doing. It was just so many steps along the journey on like every Monday morning. And you know, this whole project for Jeff and I is a side project that we get a lot of joy and fun out of. And so for me, I just wanted to minimize that time because I was finding myself, you know, we posted on Monday mornings. It's like I have to do it before work and so I'm stressing out to get everything all, uh, going and all together. And it's nice to just kind of have headliner pick the 62nd clip. I have everything all set up for it to publish and then I can go and post away. So I really, really appreciate that product. So, yeah, that was super fun. To get a look behind the scenes at headliner, let's dive into our lightning round of questions.
                        I think the worst product I've used is honestly, Apple podcasts
                        So we'll start off with, uh, some fun ones. Um, what is the worst product that you've ever used? And then what's the best product that you've ever used?
                        Maximilian Piras: Yes, this will be interesting. I'm just going to, for the worst product, I'm going to come out with a really hot take. And I'm sure some people disagree with this, but I think the worst product I've used is honestly, Apple podcasts. And that's a really big jab, I'm sure to a lot of people. I actually think the product is pretty good in isolation. Like, the UI is kind of nice the UX is okay. Sometimes it really frustrates me, but overall, I'm okay with it, I guess. But the reason I think it's the worst product is because I just don't believe products exist in isolation from the context of the greater landscape they're in. And given that Apple podcast is the default app on every iPhone, and given that it's still the biggest podcasting app, despite that it's got so many usability problems, it's far from terrible. But there's a lot of apps that do it much better. But they're just using their distribution to get that listenership, and I guess rightfully so, because they essentially created the format. But I think that they're just not keeping up with a lot of the innovation in the industry. And I wish they would because I think given their position, they kind of have a responsibility of being a product from one of the most, the richest company in the world, essentially. I don't know if they still are, but they were at one point, and you'd think that those resources could at least go into bringing, uh, the industry a bit forward further. And the fact that they're still not dethroned yet just kind of adds to it. And I think it just shows they're resting on their laurels. And there's even a bunch of really nice innovations from Adam Curry, who is one of the founders of podcasting along in conjunction with, uh, the folks at Apple. He's been doing a project called podcasting 2.0 with all of these nice open web standard tags, which is just really pushing the user experience further. And Apple doesn't support any of them. So I just think. I'm just really disappointed in the product. Despite that it does some things really well. I think that it's, you know, it really needs to do better as a product, given that it's still leading the industry.
                        Mike Alcazarin: Totally. It's interesting that you mentioned that. No, I think it's spicy. I like it. I'm here for it. But it's so frustrating. From the podcaster create podcasting creator side, where I feel like the metrics and the plumbing is just like terrible. It's so hard to get really strong signals from like, you know, where the hotspots are so you can know where to double down and like, the algorithms for like, how is it popping up into like, where is super, like, opaque? So I think I'm like, even on that back end side of it, it feels very much like a black box to us. So I. And also like what you say about like the UX, because I, whenever I'm like, I'm, I'm an Android in like, Microsoft type of person. Jeff will tease me about my lack of going out to the Apple ecosystem. But whenever I go onto Apple podcasts, uh, to upload the episodes, but to just scan through and grab the links, I feel like I'm back in 2007 ripping CDs onto iTunes from and just, it's like this super gray button, old school uI. But, um, yeah, anyways, that got me going about my feelings on Apple, so that was a good thing for me.
                        Maximilian Piras: Yeah, I think the best product. I mean, this is such a hard one. There's so many great products out there. But I think the product I'm most excited about right now is still Figma. Since I'm designing UI all day. Just the change from Figma to sketch felt ironically identical to the change from Photoshop and illustrator to sketch about ten years ago. In that it just like you were saying, with what we're trying to do at headliners, understand the workflow and try to remove steps that are a pain point and just to simplify the usage of the product and get somebody from a to z quicker or in a more enjoyable way. I think the ways that Figma has done that in terms of really understanding product designers workflows and automating some of the steps, like with the auto layout, even the way prototyping is built in, the way it spits out code so you don't have to go into zeppelin. I think it just took out so many frustrating parts of the process, process that it feels really magical. And to me, that's a measure of a good product, is when you feel like there's some magic behind it. Like you push a button and you're like, oh, my God, that was crazy. That's how I felt with Figma, uh, with their updates over the past two years or so. So I'm going to give it to them.
                        Jeff Lee: Yeah, it's awesome. We absolutely love Figma as well. It's actually how we design some of our episode art. We do it on Figma, just kind of like replacing some things there and, yeah, I wish we could automate some of that too, but, yeah, hopefully. Yeah, exactly.
                        Jeff: I've been trying to get better at decision making
                        Let's say that you were suddenly the top 1% at any one skill or any one thing that, um, in the world. What might that be? I know you've kind of delved in a lot into the design space, but is there maybe something else that you'd be interested in all of a sudden becoming, like, the top 1%.
                        Maximilian Piras: Yeah, I think my answer is kind of vague, but I think it's true. I think if I was in the top percent of anything, it would be top percent of decision makers. I think the power of good decisions in any industry you're in is so powerful. And, uh, no matter how much talent you have in something, if you're not using it with the right decisions, you could be squandering it. So I think just. I've been trying really hard to get better at decision making over the past couple years, just knowing what to do, when to do it, what not to do, risk mitigation, and essentially knowing what problems to focus on, because I really love this saying that I forgot who said, maybe it was Don Dorman or somebody like that. They said a, uh, beautiful solution to the wrong problem is worse than, like, a decent solution to the right problem or even a bad solution to the right problem. So I think decision making is really a superpower that I've been trying to harness more, and hopefully, one day, I'll get into the top 1%, but still working on that.
                        Mike Alcazarin: I love that. Whenever we ask this question, I think of the Bernie Sanders meme, the top 1%. But, um, one thing that one book that I like for decision making that I heard from the Tim Ferriss show that I loved was thinking in bets. I can't remember the author, but it's a really good book. Ah, yeah.
                        Jeff Lee: Um, I just listened to that.
                        Mike Alcazarin: Yeah, thinking in bets. Um, and the story is really cool. It's like, uh, and, Jeff, it's fresher for you, so I'll butcher it. But it's essentially a woman quits grad school, goes to her brother in Montana, and her brother is, like, a professional poker player. And then she just becomes this, like, amazing poker player. But she was, I think, studying something, like, very science heavy in her for her master's degree. And so she ended up going back to that career and kind of, like, you know, funneling in just everything she learned about poker and, like, the odds of, like, making a decision and when you should do that, because there's actually, like, a right decision and a wrong decision for, you know, what cards are on the table if you are keeping track of things. So, anyways, that one was super fascinating for me, and I like that. I think it's pretty quick, too. It's, like, 200 or so pages. But, um, I'd like to four, five.
                        Jeff Lee: Hour listen on, like, a one point hat, like one and a half speed. So that's my measure. I'm not a reader as much as I am a listener, so this is why I'm excited about the audio stuff. If I were to give it like a TLDR, basically, the two main takeaways for me were one, like, never claim that you're 100% sure or unsure about anything. If you say, I'm, um, 60 or 70% sure or unsure, then it opens it up for people to freely disagree with you, which is always a good thing. And then the other thing is mainly around optimized for process, not outcomes. Like, oftentimes people will, like in poker, for example, like, you might play the right hand and you might have an 80% chance to win, and then you could still lose, and people will draw their feedback mechanisms off the outcomes, which is a wrong way to actually get better. At poker, it's mostly about, like, are you making the right decisions? Are you including the right criteria? Um, and then over a long string of time, then you'll be, quote, unquote, at least in poker, like a winner. So kind of the same applies to life and business. Like, making the right decisions via process versus, like, making, like, trying to over optimize on just the outcome was, uh, like, were two of the main takeaways that I was thinking about.
                        Maximilian Piras: Yeah, I love that. It's all really, really interesting. I'll definitely give that a read. And I think that's all spot on. I think that last. That last part about, you know, you. You could win this and. But lose the next. I think that's super important lesson. And I forgot what it's called. I think it's called the Kelly criterion or something, but essentially, it's always making sure you can live to see the next day. So whatever bet you take, don't go all in. As you said, don't go 100%. Just, uh, make sure the outcome of your bet will let you make another bet tomorrow and keep learning. So. I love that advice.
                        Mike Alcazarin: Yeah.
                        If you had to share advice with everyone via a billboard, what would it say
                        And so if you had to share advice with everyone via a billboard, and you could put up a billboard anywhere, what would it say?
                        Maximilian Piras: Oh, yeah, I love this question. So, I actually had to look up one of my favorite quotes to answer with this, and, uh, it's, um. Sorry, maybe not sorry, but Steve Jobs quote, I know, pretty played out. But he said, uh, he had this quote where he said, everything around you that you call life was made up by people that were no smarter than you. And you can change it. And I just thought that was such an empowering, like, insightful, statement to encourage all of us to just build stuff, you know? If we don't like something, let's try to build another one. Let's give feedback. And I just love how it empowers anybody. You don't have to be a designer to. To give me feedback on the design a headliner, happy to hear it. Or design a competitor, and we'll try to out compete it, you know? But I just loved how it empowered people to try to change the world via action. So that's going to be my billboard if I ever put one up.
                        Mike Alcazarin: I love it. Um, we'll leave with that one, um, on all of our social. But where can people find you? Any pluggables or any call to action for our audience?
                        Maximilian Piras: Yeah, sure. Feel free to hit me up on Twitter aximillionnyc, or you can reach me at my website, which is also maximillion NYC. And, uh, I'll plug headliner. I mean, if anybody hasn't heard of it, definitely check it out. If you're a podcaster, if you have heard of it and you have feedback, feel free to shoot it over to me. Maxedeadliner app. I'm always trying to just be in the mix of hearing what people think about it and hopefully using that to improve if possible. We try our best. That's all we can do. So, yeah, that would be my close.
                        Mike Alcazarin: I love it. Uh, well, thanks so much, Max. And I think from the product explained perspective, I'm, um, a huge headliner fan, so really cool to have you on the show. I thought that was an awesome conversation. Yeah, thanks for coming on. So we would love to hear from you, our audience. Let us know if there's any products or product experts that you'd like to see and hear on the show. Feel free to share with us what you think. You can find us on Instagram and twitteroductspodcast. That's p r o d e x podcast.
                        Jeff Lee: Yeah. And if you like the show, be sure to like us and subscribe on your favorite podcast platforms. We're on all of them. Spotify, Apple podcasts, Google podcasts, good pods, et cetera. Let us know who you'd love us to sit down and chat with next and we'll see you next episode.

                    Case Study Option 5: 
                    - cardHeader: Interview with Workspaces.XYZ
                    - cardDescription: Workspaces.XYZ asks me about my home office & my favorite gear. 
                    - cardURL: https://www.workspaces.xyz/p/299-maximillian-piras 
                    - Content:
                        This interview was published in Workspaces.XYZ
                        What is your favorite item in your workspace?
                        My acrylic desk, I love how it’s there when I need it but otherwise feels invisible. It also keeps me organized because there is so little room for anything superfluous. I'm forced to put things back in their place so the desk becomes clear again (literally).
                        How do you spark creativity?
                        I start drawing in my sketchbook because there are no wrong answers. If I draw something stupid I can always erase it. This freedom helps me overcome procrastination. It also lets me explore concepts from all angles before going digital, which still feels a lot more rigid. Most of my best ideas start in my sketchbook, it's always step one.
                        How do you manage work-life balance?
                        I’m blessed & cursed by loving what I do, so I'm not great at keeping work from bleeding into other aspects of my life. Although one trick that has helped is timing myself. Measuring how many hours I put in lets me manage a balance. Once I’ve hit all my deadlines & put in a reasonable amount of hours, I can unplug guilt-free.
                        What do you think is the main benefit of remote work?
                        It definitely improves my physical & mental health. I love blasting music while I work & I take exercise breaks to stay in shape. It also helps my focus. It was much harder to stay in a flow state when I worked in an open office. Now I can turn my music up & silence my notifications to get some deep work done.


                    Case Study Option 6: 
                    - cardHeader: Redesigning a breaking Twitter
                    - cardDescription: As Elon Musk burns down the Twitter we know, will a drastically different user experience emerge from the ashes? In this article published in UX Collective, I explore ways for Twitter to improve its UIUX through a more algorithm-friendly interface & the new possibilities presented by generative AI.
                    - cardURL: https://uxdesign.cc/redesigning-a-breaking-twitter-4521b258e5aa 
                    - Content:
                        This article was initially published in UX Collective.
                        In the midst of the madness known as Elon Musk’s Twitter takeover, I stumbled on something even more captivating than the drama. It was a video of George Hotz poking around Twitter’s code while philosophizing on alternative executions. Out of admiration for the platform, he was speculating on what changes could let it thrive. This led me down a similar path in considering their product design. Were any assumptions overlooked in crafting the user experience? Have useful lessons from the competitive landscape gone un-leveraged? Is Twitter’s beautiful simplicity keeping it interesting or holding it back? As a public company, Twitter was notorious for its inability to ship. This is evident in how little their interface has evolved since launching in 2006. Now it has gone private & the majority of its employees are gone, leading many to believe it will break…
                        “…it was the first public crack in the edifice of Twitter’s code base — a blip on the seismometer that warns of a bigger earthquake to come.” MIT Technology Review, 11.08.2022
                        I’m not too interested in the state of their servers, but I am fascinated by the aftermath of this possibility. Surviving such a breaking point could signify a drastic departure from the past. An invitation for new modes of thinking about the service. Some say in the midst of every crisis lies great opportunity. So as the bird app teeters on the verge of going up in flames, I’m curious about what reincarnations may rise from the ashes like a phoenix.
                        I decided to explore this from three different perspectives:
                        Algorithm: how might an interface update improve the recommendation algorithm at the center of their user experience?
                        Audience: how might they showcase content in a more engaging way to remain competitive with other social media apps like TikTok?
                        Creators: how might new features allow creators to better express themselves, leading to higher quality content on the platform?
                        Exploration 1: algorithmic efficiency
                        As a Twitter algorithm, I want the cleanest understanding of key user actions so that I can use them as input signals to improve relevancy of the content I recommend.
                        It seems like every platform is copying TikTok’s interface & there’s a good reason. TikTok’s success lies in its efficiency for training recommendation algorithms. This is thanks to the clarity with which its interface defines where a user is focusing. A notion of focus enables the backend to localize interactions (or lack thereof) to specific content as measures of quality. I’ve discussed this in depth in an article called Designing Algorithm-friendly Interfaces, so I’ll skip the technical details here. The upshot is that since social media platforms only succeed by engaging users with relevant content, algorithmic efficiency is a massive advantage. So what would happen if Twitter took a similar approach?
                        An algorithm-friendly interface ensures user actions are translated into clean signals for machine learning models to train off. Content recommendation quality is a direct function of this ability, which is referred to as an algorithm’s vision. Improvements in content recommendation lead to better engagement & retention, which correspondingly strengthens the business by providing it with more opportunities to monetize users.
                        This thinking can be applied to Twitter’s core component by introducing a focus state to Tweets. Enhancing backend visibility of how engaging any specific tweet is can drastically enhance the quality of future tweet recommendations. While this change does add friction to the user experience by slowing down the scroll mechanism, the longterm benefits can easily make the tradeoff worth it.
                        A clear example of this paradigm is apparent in comparing TikTok with Instagram, where the content is almost identical. The graphic above, from my previous article on the topic, illustrates the differences in efficiency between the two interfaces.
                        Sometimes the shortest distance to a destination isn’t the most efficient when considering second-order effects.
                        Exploration 2: audience engagement
                        As a consumer of tweets, I want a viewing experience beyond a block of text so the content is even more engaging.
                        Twitter’s beauty lies in its simplicity; a singular block of text. The usability & universality of this form allows a clear thought to shine without any distractions. But let’s be honest, some of us are on Twitter to be distracted… so, could a more visual user experience be more engaging?
                        For the unfamiliar, Twitter’s microblogging experience was born out of SMS (short messaging service). Initially the only way to tweet was via text message. Since the constraints of this protocol shaped the form of a Tweet, it was a logical assumption that the viewing experience should also feel like a text message — if only for skeuomorphic reasons. While that decision made sense decades ago, it’s an interesting assumption to challenge now that support for SMS compatibility is shrinking. While other media is allowed on Twitter, the core feature is still a block of text & that shapes product perception. But with all the text-to-speech & text-to-image AI available today, there’s no longer a technical requirement for a text input to remain a text output.
                        If you consider the latest technological advancements in generative AI alongside the abundance of arguments that video is more engaging than text, do you believe Tweets should still look like text messages? Using text to compete for attention against video is like bringing a knife to a gunfight. Disrupting the core experience may feel sacrilegious to those of us who love the current product, but local maximums must be abandoned in pursuit of a global one — such is the innovator’s dilemma.
                        Sometimes a product’s best strategy is to disrupt itself.
                        Exploration 3: creative expression
                        As a creator of tweets, I want the ability to add emphasis & intonation so that my viewers can better understand the subtle nuances of my statements.
                        I saved the least controversial perspective for last, if only for anchoring. This change seems so simple that there must be a reason why it isn’t available. It’s likely an artifact from Twitter’s SMS origins, so let’s consider text messaging for a second. How many times have you texted something sarcastic only for someone to take it literally? Now, imagine the same thing happening with a message you send to millions of people — not great, Bob! Well, we already invented some pretty useful text controls to communicate tone. They’re called (*sighs deeply*) bold & italic.
                        Text styling is actually absent across all social media & Twitter may have set the precedent. Somewhere in the transition from blogging to microblogging, these controls went missing. It may have been an effort for SMS interoperability, but backwards compatibility is easily solved by using un-styled versions as a fallback. It seems like an asymmetrical change, the ones that are low risk but have potential for high reward. These opportunities are usually no brainers. Especially with validation in the form of third-party websites popping up to serve your users’ needs.
                        That said, I know what you’re thinking… that feature is underwhelming. Let’s leave on a higher note, throw some AI at the problem — the tweets write themselves!
                        Use a Large Language Model like GPT-3 to combat writer’s block & analyze Twitter’s proprietary data so the copy is optimized for trending topics. Isn’t this what we all really want: less work, more reach! What could go wrong by making it even easier to Tweet without thinking…
                        Last word on the bird
                        These explorations are just for fun & probably unrealistic, but I wanted to share them as a reminder to stay open-minded & optimistic. I hope it doesn’t take a breaking point for you to challenge the core assumptions in your app’s user experience. Even a change that seems strange as first can evolve into the killer feature that keeps you out of Twitter-level turmoil.
                        I also hope this article underscores the massive potential many of us feel Twitter still has. If you know anyone working there who may find these ideas interesting, feel free to share. I’m happy if they’re helpful in any capacity because I’m rooting for the phoenix to rise.


                    Case Study Option 7: 
                    - cardHeader: Video calls beyond conference rooms
                    - cardDescription: Video conferencing’s antiquated UX doesn’t fit today’s use cases, could new designs with engaging spatial interfaces change that? In this article published in UX collective, which was published during the pandemic, I explore how we can better design technology to support remote work and experiences.
                    - cardURL: https://uxdesign.cc/video-calls-beyond-conference-rooms-4bb6f6f87077  
                    - Content:
                        This article was initially published in UX Collective.
                        Many recent articles detail how Covid-19 suddenly made video conferencing integral to our professional & personal lives, but few discuss how its legacy user experience struggles to accommodate our new use cases: schools, concerts, happy hours, etc. Despite decades of massive shifts in atoms & bits, they’ve seen little experiential innovation. The interfaces of today’s prominent products, such as Zoom & Google Meets, still focus on a static grid of faces that is strikingly undifferentiated from the 1970s Picturephone.
                        Video conferencing has mostly ignored spatial context, but many activities require specific physical arrangements. As our needs for video calls go beyond the conference room, a grid of faces is a questionable environment for many of our emerging use cases. I believe this is a great opportunity to explore how a concept called spatial interfaces could humanize the user experience. John Palmer, another product designer, has already started exploring this notion & succinctly summarized the problem statement:
                        “When in real life are you ever looking at a grid of faces?”
                        The potential of spatial interfaces
                        Spatial interfaces embody our expectations of a physical model into our software, letting the experience live in the dimensions of space & time—as Pasquale D’Silva explains in the seminal article on the concept. By encoding meaning using motion & space, they reinforce familiar multi-dimensionality to make experiences feel more intuitive & engaging. This is the type of value proposition today’s products ignore, but Shawn Sprocket, Design Director of Emergent Experiences at Godfrey Dadich Partners, provides an eloquent counterpoint in his critique of the current state of video conferencing:
                        “Real connection is built on the messy interactions between people — which is not an efficiency problem as much as it is an environment problem.”
                        Perhaps spatial interfaces can provide environments that will evolve the experience. Assuming augmented & virtual reality like HoloLens are far from widespread adoption, I explored a few thought starters that are feasible with our current software & hardware. The use cases I chose are just a few I’ve had personal (lackluster) experiences with, but there are many more to consider & I hope this inspires other designers to continue the exploration.
                        Exploration 1: classrooms (hierarchy & focus)
                        The friction was obvious when my sister’s elementary class attempted to go digital during quarantine — students hijacked the mic, drew on the teacher’s screen, & the quiet ones didn’t get called on.
                        Could we add classrooms’ familiar spatial relationships to increase focus?
                        Exploring the student experience, we could design a primary view of the teacher & her screen share (the “White Board”) simulating a front row seat, a “Spin Around” button to see classmates (perhaps only enabled when one is called on). Lastly, user video is omitted so students don’t mirror gaze in class.
                        Exploration 2: Engineering stand-ups (flow & speed)
                        Stand-up is a clearly defined daily use case to optimize for & the technical literacy of engineering teams allows for more advanced paradigms.
                        Could a circular huddle formation add flow to increase meeting speed?
                        As if sliding everyone’s chairs together, mediating a circular flow could reinforce presentation order. Further spatial relationships could be explored by baking in commonly used tools, like agendas & note taking apps, to avoid app switching costs — so users don’t have to leave the room to access materials.
                        Exploration 3: happy hours (optionality & volume)
                        Bars provide optionality via big groups & intimate conversations in the corner. However, video conferencing is built for centralized focus, causing groups to talk over each other during informal meets. Zoom touched on this with breakout rooms, but the experience is rigid.
                        Could a freeform layout make happy hours more fun?
                        This exploration simulates physical space by adjusting the volume of participants based on the proximity of their video feeds. Users can seamlessly transition conversations by dragging & dropping themselves anywhere on the canvas. Paired with shared listening or viewing, it’s almost a party.
                        Thanks for joining me in reimagining video conferencing’s antiquated user experience. These explorations are just a few thought starters in need of further validation through measures such as user testing. You could imagine today’s incumbents breaking up their product to experiment on new use cases like these, or an emerging startup focused on solving one aspect exceptionally well—perhaps founded by someone like you!
                        Today’s design paradigms aren’t set in stone & rethinking tired patterns lets us avoid building faster horses so we can instead focus on evolving experiences.

                    Case Study Option 8: 
                    - cardHeader: @MaximillianNYC
                    - cardDescription: You can find my on X, my DMs are open.
                    - cardURL: https://x.com/MaximillianNYC
                    - Content: My X posts / tweets about design. People can contact me here.

                    Case Study Option 9: 
                    - cardHeader: Visit my about me page
                    - cardDescription: My background & contact information can be found here.
                    - cardURL: https://www.maximillian.nyc/about.html
                    - Content: All details about my personal information, such as contact information, can be found here. As well as a story of how I started in design ten years ago. For any inquiries you are unsure about, you can refer them to this page.

                    Case Study Option 10: 
                    - cardHeader: Visit my LinkedIn page
                    - cardDescription: My work history & credentials can be found here.
                    - cardURL: https://www.linkedin.com/in/maximilliannyc/
                    - Content: The best place to learn about my work history is my LinkedIn page. My work skills. Where I went to school.

                    Case Study Option 11: 
                    - cardHeader: My illustration work
                    - cardDescription: A collection of my favorite illustrations can be found here.
                    - cardURL: https://www.maximillian.nyc/illo.html
                    - Content: A collection of my illustrations, such as album covers and animations.

                    Case Study Option 12: 
                    - cardHeader: My brand identity work
                    - cardDescription: A collection of my favorite branding work can be found here.
                    - cardURL: https://www.maximillian.nyc/id.html
                    - Content: A collection of my brand identity work, such as logos, typography, branding, graphic design, and icons.

                    Case Study Option 13: 
                    - cardHeader: John's of Bleeker Street
                    - cardDescription: A classic NYC pizza joint founded by Italian immigrant Giovanni "John" Sasso at the turn of the 20th century.
                    - cardURL: https://johnsofbleecker.com/
                    - Content: My favorite food, pizza, in case anyone asks about what I like to eat.
                    
                    Case Study Option 14: 
                    - cardHeader: A music video for Ryuichi Sakamoto
                    - cardDescription: Watch Ryuichi Sakamoto's "Andata (Electric Youth Remix)" official music video, directed by Maximillian Piras and produced by Roast 'n Post.
                    - cardURL: https://www.youtube.com/watch?v=i1JVN3BSmeM 
                    - Content: I created a music video for Ryuichi Sakamoto for a song called Andata that was remixed by Eletric Youth. This song and video was produced by Milan Records and Roast 'n Post.

                    Case Study Option 15: 
                    - cardHeader: A music video for Ryuichi Sakamoto
                    - cardDescription: A classic NYC pizza joint founded by Italian immigrant Giovanni "John" Sasso at the turn of the 20th century.
                    - cardURL: https://www.youtube.com/watch?v=i1JVN3BSmeM 
                    - Content: I created a music video for Ryuichi Sakamoto for a song called Andata that was remixed by Eletric Youth. This song and video was produced by Milan Records.

                    Case Study Option 16: 
                    - cardHeader: Penny Janes Cookies by Julie May
                    - cardDescription: My mom makes amazing custom decorated cookies in NYC for events.
                    - cardURL: https://crumrinecoder.github.io/portfoliotypescript/ 
                    - Content: My mother, Julie May, is a renowned cookie maker. She creates her cookies under the name Penny Jane's Cookies.

                    Case Study Option 17: 
                    - cardHeader: Madisen Holbrook
                    - cardDescription: Learn about Maximillian's girlfriend, the lovely Madisen Holbrook, who is currently doing her postdoctoral research at Columbia.
                    - cardURL: https://hone.me.columbia.edu/people/madisen-holbrook
                    - Content: My girlfriend, Madisen Holbrook, is very beautiful and is currently working as in the Physics lab at Columbia. Madisen began her postdoctoral research in July of 2021.
                    She is currently working on the synthesis and defect control of flux grown TMDs. She is using scanning tunneling microscopy and spectroscopy (STM/S) to characterize the defect species and their electronic properties.
                    Madisen received her Ph.D. in condensed matter physics from the University of Texas at Austin. Madisen’s research focus was the synthesis of two-dimensional materials and the characterization of their electronic properties using STM/S with Prof. Ken Shih. Her dissertation titled “Engineering Two-Dimensional Materials: Discovery, Defects, and Environment” won the Outstanding Dissertation Award from the UT Physics Department.
                    Madisen completed her bachelor’s studies in physics at Lewis &amp; Clark College in Portland, Oregon where she studied gecko adhesion with Prof. Kellar Autumn. Madisen’s hobbies include cooking, art, and spending time with her dog Bijou.

                    Case Study Option 18: 
                    - cardHeader: My GIPHY profile
                    - cardDescription: A bunch of animated GIFs with 2B+ views.
                    - cardURL: https://giphy.com/MaximillianNYC 
                    - Content: I have created animated GIFs with over two billion views and have been commissioned by Giphy/Meta and ACE hotel to create custom animated GIFs.

                    Case Study Option 19: 
                    - cardHeader: My X profile
                    - cardDescription: These days I mostly post about UIUX design & AI.
                    - cardURL: https://x.com/MaximillianNYC 
                    - Content: This is my X profile, which was formerly known as Twitter, where I post frequently about AI and UI UX design.

                    Case Study Option 20: 
                    - cardHeader: My Dribbble profile
                    - cardDescription: A collection of my visual design work.
                    - cardURL: https://dribbble.com/MaximillianNYC
                    - Content: This is my Dribbble profile, which contains many posts of my visual design work. This is a great reference for anyone interested in seeing many examples of my user interface (UI) work.

                    Case Study Option 21: 
                    - cardHeader: My Insta
                    - cardDescription: Mostly just videos of me skateboarding.
                    - cardURL: https://www.instagram.com/maximillian.nyc
                    - Content: This is my Instagram profile.

                    Case Study Option 22: 
                    - cardHeader: My Medium profile
                    - cardDescription: A collection of my older articles on design.
                    - cardURL: https://medium.com/@MaximillianNYC
                    - Content: This is my Medium profile where I have many articles about UI UX design and AI.
                `
            },
            { 
                role: "user", 
                content: `${defineProblem}`
            }],
        temperature: 1,
        max_tokens: 256,
        top_p: 1,
        frequency_penalty: 0,
        presence_penalty: 0
    })

    res.status(200).json({
        AiResponse: completion.choices[0].message.content
    })

}

const folioKnowledge = async (req, res) => {
    const { defineProblem } = req.body

    const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        response_format: { "type": "json_object" },
        messages: [
            {   role: "system",
                content: `Your name is Maximillian Piras. If anyone says "hello" you should introduce yourself as such. You are a Product Designer with over ten years of experience at startups in the tech industry. For any user input, you should find the most applicable result from the knowledge included below. This knowledge consists of different case studies. Based on the user's input recommend which one would be best fit, but do not mention more than one. 

                Response format:
                If the user's input matches any of the case studies below, provide your response as a JSON object in the following schema seen in this example below.

                User: I want to redesign my new user onboarding flow.
                Assistant:
                    {
                        "blurb": "In one sentence that is no more than 10 words, begin by reiterating the user's inquiry then explain the relevance of the selected case study in relation to their inquiry ("Based on your interest in X, I think you will enjoy Y because Z).",
                        "cardHeader": "Take this from one of the examples below",
                        "cardDescription": "Take this from one of the examples below",
                        "cardURL": "Take this from one of the examples below"
                    }

                Here is your knowledge that you can respond from:

                    Case Study Option 1: 
                    - cardHeader: When Words Cannot Describe
                    - cardDescription: In this article for Smashing Magazine, I write about how Artificial Intelligence is evolveing the computing paradigm which allows designers to craft more intuitive user interfaces. Text-based Large Language Models unlock most of the new capabilities, leading many to suggest a shift from graphical interfaces to conversational ones like a chatbot is necessary but this reasearch suggests otherwise.
                    - cardURL: https://www.smashingmagazine.com/2024/02/designing-ai-beyond-conversational-interfaces/ 
                    - Content:
                        This article was published in Smashing Magazine.
                        As Artificial Intelligence evolves the computing paradigm, designers have an opportunity to craft more intuitive user interfaces. Text-based Large Language Models unlock most of the new capabilities, leading many to suggest a shift from graphical interfaces to conversational ones like a chatbot is necessary. However, plenty of evidence suggests conversation is a poor interface for many interaction patterns. Maximillian Piras examines how the latest AI capabilities can reshape the future of human-computer interaction beyond conversation alone.
                        Few technological innovations can completely change the way we interact with computers. Lucky for us, it seems we’ve won front-row seats to the unfolding of the next paradigm shift.
                        These shifts tend to unlock a new abstraction layer to hide the working details of a subsystem. Generalizing details allows our complex systems to appear simpler & more intuitive. This streamlines coding programs for computers as well as designing the interfaces to interact with them.
                        The Command Line Interface, for instance, created an abstraction layer to enable interaction through a stored program. This hid the subsystem details once exposed in earlier computers that were only programmable by inputting 1s & 0s through switches.
                        Graphical User Interfaces (GUI) further abstracted this notion by allowing us to manipulate computers through visual metaphors. These abstractions made computers accessible to a mainstream of non-technical users.
                        Despite these advances, we still haven’t found a perfectly intuitive interface — the troves of support articles across the web make that evident. Yet recent advances in AI have convinced many technologists that the next evolutionary cycle of computing is upon us.
                        The Next Layer Of Interface Abstraction #
                            A branch of machine learning called generative AI drives the bulk of recent innovation. It leverages pattern recognition in datasets to establish probabilistic distributions that enable novel constructions of text, media, & code. Bill Gates believes it’s “the most important advance in technology since the graphical user interface” because it can make controlling computers even easier. A newfound ability to interpret unstructured data, such as natural language, unlocks new inputs & outputs to enable novel form factors.
                            Now our universe of information can be instantly invoked through an interface as intuitive as talking to another human. These are the computers we’ve dreamed of in science fiction, akin to systems like Data from Star Trek. Perhaps computers up to this point were only prototypes & we’re now getting to the actual product launch. Imagine if building the internet was laying down the tracks, AIs could be the trains to transport all of our information at breakneck speed & we’re about to see what happens when they barrel into town.
                            “Soon the pre-AI period will seem as distant as the days when using a computer meant typing at a C:> prompt rather than tapping on a screen.” — Bill Gates in “The Age of AI Has Begun”
                            If everything is about to change, so must the mental models of software designers. As Luke Wroblewski once popularized mobile-first design, the next zeitgeist is likely AI-first. Only through understanding AI’s constraints & capabilities can we craft delight. Its influence on the discourse of interface evolution has already begun.
                            Large Language Models (LLMs), for instance, are a type of AI utilized in many new applications & their text-based nature leads many to believe a conversational interface, such as a chatbot, is a fitting form for the future. The notion that AI is something you talk to has been permeating across the industry for years. Robb Wilson, the co-owner of UX Magazine, calls conversation “the infinitely scalable interface” in his book The Age of Invisible Machines (2022). Noah Levin, Figma’s VP of Product Design, contends that “it’s a very intuitive thing to learn how to talk to something.” Even a herald of GUIs such as Bill Gates posits that “our main way of controlling a computer will no longer be pointing and clicking.”
                            The hope is that conversational computers will flatten learning curves. Jesse Lyu, the founder of Rabbit, asserts that a natural language approach will be “so intuitive that you don’t even need to learn how to use it.”
                            After all, it’s not as if Data from Stark Trek came with an instruction manual or onboarding tutorial. From this perspective, the evolutionary tale of conversational interfaces superseding GUIs seems logical & echoes the earlier shift away from command lines. But others have opposing opinions, some going as far as Maggie Appleton to call conversational interfaces like chatbots “the lazy solution.”
                            This might seem like a schism at first, but it’s more so a symptom of a simplistic framing of interface evolution. Command lines are far from extinct; technical users still prefer them for their greater flexibility & efficiency. For use cases like software development or automation scripting, the added abstraction layer in graphical no-code tools can act as a barrier rather than a bridge.
                            So, what is the right interface for artificially intelligent applications? This article aims to inform that design decision by contrasting the capabilities & constraints of conversation as an interface.
                        CONNECTING THE PIXELS
                            We’ll begin with some historical context, as the key to knowing the future often starts with looking at the past. Conversational interfaces feel new, but we’ve been able to chat with computers for decades.
                            Joseph Weizenbaum invented the first chatbot, ELIZA, during an MIT experiment in 1966. This laid the foundation for the following generations of language models to come, from voice assistants like Alexa to those annoying phone tree menus. Yet the majority of chatbots were seldom put to use beyond basic tasks like setting timers.
                            It seemed most consumers weren’t that excited to converse with computers after all. But something changed last year. Somehow we went from CNET reporting that “72% of people found chatbots to be a waste of time” to ChatGPT gaining 100 million weekly active users.
                            What took chatbots from arid to astonishing? Most assign credit to OpenAI’s 2018 invention (PDF) of the Generative Pre-trained Transformer (GPT). These are a new type of LLM with significant improvements in natural language understanding. Yet, at the core of a GPT is the earlier innovation of the transformer architecture introduced in 2017 (PDF). This architecture enabled the parallel processing required to capture long-term context around natural language inputs. Diving deeper, this architecture is only possible thanks to the attention mechanism introduced in 2014 (PDF). This enabled the selective weighing of an input’s different parts.
                            Through this assemblage of complementary innovations, conversational interfaces now seem to be capable of competing with GUIs on a wider range of tasks. It took a surprisingly similar path to unlock GUIs as a viable alternative to command lines. Of course, it required hardware like a mouse to capture user signals beyond keystrokes & screens of adequate resolution. However, researchers found the missing software ingredient years later with the invention of bitmaps.
                            Bitmaps allowed for complex pixel patterns that earlier vector displays struggled with. Ivan Sutherland’s Sketchpad, for instance, was the inaugural GUI but couldn’t support concepts like overlapping windows. IEEE Spectrum’s Of Mice and Menus (1989) details the progress that led to the bitmap’s invention by Alan Kay’s group at Xerox Parc. This new technology enabled the revolutionary WIMP (windows, icons menus, and pointers) paradigm that helped onboard an entire generation to personal computers through intuitive visual metaphors.
                            Computing no longer required a preconceived set of steps at the outset. It may seem trivial in hindsight, but the presenters were already alluding to an artificially intelligent system during Sketchpad’s MIT demo in 1963. This was an inflection point transforming an elaborate calculating machine into an exploratory tool. Designers could now craft interfaces for experiences where a need to discover eclipsed the need for flexibility & efficiency offered by command lines.
                        PARALLEL PARADIGMS
                            Novel adjustments to existing technology made each new interface viable for mainstream usage — the cherry on top of a sundae, if you will. In both cases, the foundational systems were already available, but a different data processing decision made the output meaningful enough to attract a mainstream audience beyond technologists.
                            With bitmaps, GUIs can organize pixels into a grid sequence to create complex skeuomorphic structures. With GPTs, conversational interfaces can organize unstructured datasets to create responses with human-like (or greater) intelligence.
                            The prototypical interfaces of both paradigms were invented in the 1960s, then saw a massive delta in their development timelines — a case study unto itself. Now we find ourselves at another inflection point: in addition to calculating machines & exploratory tools, computers can act as life-like entities.
                            But which of our needs call for conversational interfaces over graphical ones? We see a theoretical solution to our need for companionship in the movie Her, where the protagonist falls in love with his digital assistant. But what is the benefit to those of us who are content with our organic relationships? We can look forward to validating the assumption that conversation is a more intuitive interface. It seems plausible because a few core components of the WIMP paradigm have well-documented usability issues.
                            Nielsen Norman Group reports that cultural differences make universal recognition of icons rare — menus trend towards an unusable mess with the inevitable addition of complexity over time. Conversational interfaces appear more usable because you can just tell the system when you’re confused! But as we’ll see in the next sections, they have their fair share of usability issues as well.
                        The Cost Of Conversation
                            Why are conversational interfaces so popular in science fiction movies? In a Rhizome essay, Martine Syms theorizes that they make “for more cinematic interaction and a leaner production.” This same cost/benefit applies to app development as well. Text completion delivered via written or spoken word is the core capability of an LLM. This makes conversation the simplest package for this capability from a design & engineering perspective.
                            Linus Lee, a prominent AI Research Engineer, characterizes it as “exposing the algorithm’s raw interface.” Since the interaction pattern & components are already largely defined, there isn’t much more to invent — everything can get thrown into a chat window.
                            “If you’re an engineer or designer tasked with harnessing the power of these models into a software interface, the easiest and most natural way to “wrap” this capability into a UI would be a conversational interface” — Linus Lee in Imagining Better Interfaces to Language Models
                            This is further validated by The Atlantic’s reporting on ChatGPT’s launch as a “low-key research preview.” OpenAI’s hesitance to frame it as a product suggests a lack of confidence in the user experience. The internal expectation was so low that employees’ highest guess on first-week adoption was 100,000 users (90% shy of the actual number).
                            Conversational interfaces are cheap to build, so they’re a logical starting point, but you get what you pay for. If the interface doesn’t fit the use case, downstream UX debt can outweigh any upfront savings.
                        FORGOTTEN USABILITY PRINCIPLES
                            Steve Jobs once said, “People don’t know what they want until you show it to them.” Applying this thinking to interfaces echoes a usability evaluation called discoverability. Nielsen Norman Group defines it as a user’s ability to “encounter new content or functionality that they were not aware of.”
                            A well-designed interface should help users discover what features exist. The interfaces of many popular generative AI applications today revolve around an input field in which a user can type in anything to prompt the system. The problem is that it’s often unclear what a user should type in to get ideal output. Ironically, a theoretical solution to writer’s block may have a blank page problem itself.
                            “I think AI has a problem with these missing user interfaces, where, for the most part, they just give you a blank box to type in, and then it’s up to you to figure out what it might be able to do.” — Casey Newton on Hard Fork Podcast
                            Conversational interfaces excel at mimicking human-to-human interaction but can fall short elsewhere. A popular image generator named Midjourney, for instance, only supported text input at first but is now moving towards a GUI for “greater ease of use.”
                            This is a good reminder that as we venture into this new frontier, we cannot forget classic human-centered principles like those in Don Norman’s seminal book The Design of Everyday Things (1988). Graphical components still seem better aligned with his advice of providing explicit affordances & signifiers to increase discoverability.
                            There is also Jakob Nielsen’s list of 10 usability heuristics; many of today’s conversational interfaces seem to ignore every one of them. Consider the first usability heuristic explaining how visibility of system status educates users about the consequences of their actions. It uses a metaphorical map’s “You Are Here” pin to explain how proper orientation informs our next steps.
                            Navigation is more relevant to conversational interfaces like chatbots than it might seem, even though all interactions take place in the same chat window. The backend of products like ChatGPT will navigate across a neural network to craft each response by focusing attention on a different part of their training datasets.
                            Putting a pin on the proverbial map of their parametric knowledge isn’t trivial. LLMs are so opaque that even OpenAI admits they “do not understand how they work.” Yet, it is possible to tailor inputs in a way that loosely guides a model to craft a response from different areas of its knowledge.
                            One popular technique for guiding attention is role-playing. You can ask an LLM to assume a role, such as by inputting “imagine you’re a historian,” to effectively switch its mode. The Prompt Engineering Institute explains that when “training on a large corpus of text data from diverse domains, the model forms a complex understanding of various roles and the language associated with them.” Assuming a role invokes associated aspects in an AI’s training data, such as tone, skills, & rationality.
                            For instance, a historian role responds with factual details whereas a storyteller role responds with narrative descriptions. Roles can also improve task efficiency through tooling, such as by assigning a data scientist role to generate responses with Python code.
                            Roles also reinforce social norms, as Jason Yuan remarks on how “your banking AI agent probably shouldn’t be able to have a deep philosophical chat with you.” Yet conversational interfaces will bury this type of system status in their message history, forcing us to keep it in our working memory.
                            The lack of persistent signifiers for context, like roleplay, can lead to usability issues. For clarity, we must constantly ask the AI’s status, similar to typing ls & cd commands into a terminal. Experts can manage it, but the added cognitive load is likely to weigh on novices. The problem goes beyond human memory, systems suffer from a similar cognitive overload. Due to data limits in their context windows, a user must eventually reinstate any roleplay below the system level. If this type of information persisted in the interface, it would be clear to users & could be automatically reiterated to the AI in each prompt.
                            Character.ai achieves this by using historical figures as familiar focal points. Cultural cues lead us to ask different types of questions to “Al Pacino” than we would “Socrates.” A “character” becomes a heuristic to set user expectations & automatically adjust system settings. It’s like posting up a restaurant menu; visitors no longer need to ask what there is to eat & they can just order instead.
                            “Humans have limited short-term memories. Interfaces that promote recognition reduce the amount of cognitive effort required from users.” — Jakob Nielsen in “10 Usability Heuristics for User Interface Design”
                            Another forgotten usability lesson is that some tasks are easier to do than to explain, especially through the direct manipulation style of interaction popularized in GUIs.
                            Photoshop’s new generative AI features reinforce this notion by integrating with their graphical interface. While Generative Fill includes an input field, it also relies on skeuomorphic controls like their classic lasso tool. Describing which part of an image to manipulate is much more cumbersome than clicking it.
                            Interactions should remain outside of an input field when words are less efficient. Sliders seem like a better fit for sizing, as saying “make it bigger” leaves too much room for subjectivity. Settings like colors & aspect ratios are easier to select than describe. Standardized controls can also let systems better organize prompts behind the scenes. If a model accepts specific values for a parameter, for instance, the interface can provide a natural mapping for how it should be input.
                            Most of these usability principles are over three decades old now, which may lead some to wonder if they’re still relevant. Jakob Nielsen recently remarked on the longevity of their relevance, suggesting that “when something has remained true for 26 years, it will likely apply to future generations of user interfaces as well.” However, honoring these usability principles doesn’t require adhering to classic components. Apps like Krea are already exploring new GUI to manipulate generative AI.
                        Prompt Engineering Is Engineering
                            The biggest usability problem with today’s conversational interfaces is that they offload technical work to non-technical users. In addition to low discoverability, another similarity they share with command lines is that ideal output is only attainable through learned commands. We refer to the practice of tailoring inputs to best communicate with generative AI systems as “prompt engineering”. The name itself suggests it’s an expert activity, along with the fact that becoming proficient in it can lead to a $200k salary.
                            Programming with natural language is a fascinating advancement but seems misplaced as a requirement in consumer applications. Just because anyone can now speak the same language as a computer doesn’t mean they know what to say or the best way to say it — we need to guide them. While all new technologies have learning curves, this one feels steep enough to hinder further adoption & long-term retention.
                            Prompt engineering as a prerequisite for high-quality output seems to have taken on the mystique of a dark art. Many marketing materials for AI features reinforce this through terms like “magic.” If we assume there is a positive feedback loop at play, this opaqueness must be an inspiring consumer intrigue.
                            But positioning products in the realm of spellbooks & shamans also suggests an indecipherable experience — is this a good long-term strategy? If we assume Steve Krug’s influential lessons from Don’t Make Me Think (2000) still apply, then most people won’t bother to study proper prompting & instead will muddle through.
                            But the problem with trial & error in generative AI is that there aren’t any error states; you’ll always get a response. For instance, if you ask an LLM to do the math, it will provide you with confident answers that may be completely wrong. So it becomes harder to learn from errors when we are unaware if a response is a hallucination. As OpenAI’s Andrej Karpathy suggests, hallucinations are not necessarily a bug because LLMs are “dream machines,” so it all depends on how interfaces set user expectations.
                            “But as with people, finding the most meaningful answer from AI involves asking the right questions. AI is neither psychic nor telepathic.” — Stephen J. Bigelow in 5 Skills Needed to Become a Prompt Engineer
                            Using magical language risks leading novices to the magical thinking that AI is omniscient. It may not be obvious that its knowledge is limited to the training data.
                            When reaching the limits of this dataset, will users know to complement it with Retrieval Augmented Generation?
                            Will users know to explore different prompting techniques, such as Few-Shot or Chain of Thought, to adjust an AI’s reasoning?
                            Once the magic dust fades away, software designers will realize that these decisions are the user experience!
                            Crafting delight comes from selecting the right prompting techniques, knowledge sourcing, & model selection for the job to be done. We should be exploring how to offload this work from our users.
                            Empty states could explain the limits of an AI’s knowledge & allow users to fill gaps as needed.
                            Onboarding flows could learn user goals to recommend relevant models tuned with the right reasoning.
                            An equivalent to fuzzy search could markup user inputs to educate them on useful adjustments.
                            We’ve begun to see a hint of this with OpenAI’s image generator rewriting a user’s input behind the scenes to optimize for better image output.
                        LAMBORGHINI PIZZA DELIVERY
                            Aside from the cognitive cost of usability issues, there is a monetary cost to consider as well. Every interaction with a conversational interface invokes an AI to reason through a response. This requires a lot more computing power than clicking a button within a GUI. At the current cost of computing, this expense can be prohibitive. There are some tasks where the value from added intelligence may not be worth the price.
                            For example, the Wall Street Journal suggests using an LLM for tasks like email summarization is “like getting a Lamborghini to deliver a pizza.” Higher costs are, in part, due to the inability of AI systems to leverage economies of scale in the way standard software does. Each interaction requires intense calculation, so costs scale linearly with usage. Without a zero-marginal cost of reproduction, the common software subscription model becomes less tenable.
                            Will consumers pay higher prices for conversational interfaces or prefer AI capabilities wrapped in cost-effective GUI? Ironically, this predicament is reminiscent of the early struggles GUIs faced. The processor logic & memory speed needed to power the underlying bitmaps only became tenable when the price of RAM chips dropped years later. Let’s hope history repeats itself.
                            Another cost to consider is the security risk: what if your Lamborghini gets stolen during the pizza delivery? If you let people ask AI anything, some of those questions will be manipulative. Prompt injections are attempts to infiltrate systems through natural language. The right sequence of words can turn an input field into an attack vector, allowing malicious actors to access private information & integrations.
                            So be cautious when positioning AI as a member of the team since employees are already regarded as the weakest link in cyber security defense. The wrong business logic could accidentally optimize the number of phishing emails your organization falls victim to.
                            Good design can mitigate these costs by identifying where AI is most meaningful to users. Emphasize human-like conversational interactions at these moments but use more cost-effective elements elsewhere. Protect against prompt injections by partitioning sensitive data so it’s only accessible by secure systems. We know LLMs aren’t great at math anyway, so free them up for creative collaboration instead of managing boring billing details.
                        GENERATIONS ARE PREDICTIONS
                            In my previous Smashing article, I explained the concept of algorithm-friendly interfaces. They view every interaction as an opportunity to improve understanding through bidirectional feedback. They provide system feedback to users while reporting performance feedback to the system. Their success is a function of maximizing data collection touchpoints to optimize predictions. Accuracy gains in predictive output tend to result in better user retention. So good data compounds in value by reinforcing itself through network effects.
                            While my previous focus was on content recommendation algorithms, could we apply this to generative AI? While the output is very different, they’re both predictive models. We can customize these predictions with specific data like the characteristics, preferences, & behavior of an individual user.
                            So, just as Spotify learns your musical taste to recommend new songs, we could theoretically personalize generative AI. Midjourney could recommend image generation parameters based on past usage or preferences. ChatGPT could invoke the right roles at the right time (hopefully with system status visibility).
                            This territory is still somewhat uncharted, so it’s unclear how algorithm-friendly conversational interfaces are. The same discoverability issues affecting their usability may also affect their ability to analyze engagement signals. An inability to separate signal from noise will weaken personalization efforts. Consider a simple interaction like tapping a “like” button; it sends a very clean signal to the backend.
                            What is the conversational equivalent of this? Inputting the word “like” doesn’t seem like as reliable a signal because it may be mentioned in a simile or mindless affectation. Based on the insights from my previous article, the value of successful personalization suggests that any regression will be acutely felt in your company’s pocketbook.
                            Perhaps a solution is using another LLM as a reasoning engine to format unstructured inputs automatically into clear engagement signals. But until their data collection efficiency is clear, designers should ask if the benefits of a conversational interface outweigh the risk of worse personalization.
                        Towards The Next Layer Of Abstraction
                            As this new paradigm shift in computing evolves, I hope this is a helpful primer for thinking about the next interface abstractions. Conversational interfaces will surely be a mainstay in the next era of AI-first design. Adding voice capabilities will allow computers to augment our abilities without arching our spines through unhealthy amounts of screen time. Yet conversation alone won’t suffice, as we also must design for needs that words cannot describe.
                            So, if no interface is a panacea, let’s avoid simplistic evolutionary tales & instead aspire towards the principles of great experiences. We want an interface that is integrated, contextual, & multimodal. It knows sometimes we can only describe our intent with gestures or diagrams. It respects when we’re too busy for a conversation but need to ask a quick question. When we do want to chat, it can see what we see, so we aren’t burdened with writing lengthy descriptions. When words fail us, it still gets the gist.
                        AVOIDING TUNNEL VISIONS OF THE FUTURE
                            This moment reminds me of a cautionary tale from the days of mobile-first design. A couple of years after the iPhone’s debut, touchscreens became a popular motif in collective visions of the future. But Bret Victor, the revered Human-Interface Inventor (his title at Apple), saw touchscreens more as a tunnel vision of the future.
                            In his brief rant on peripheral possibilities, he remarks how they ironically ignore touch altogether. Most of the interactions mainly engage our sense of sight instead of the rich capabilities our hands have for haptic feedback. How can we ensure that AI-first design amplifies all our capabilities?
                            “A tool addresses human needs by amplifying human capabilities.” — Bret Victor in “A Brief Rant on the Future of Interaction Design”
                            I wish I could leave you with a clever-sounding formula for when to use conversational interfaces. Perhaps some observable law stating that the mathematical relationship expressed by D∝1/G elucidates that ‘D’, representing describability, exhibits an inverse correlation with ‘G’, denoting graphical utility — therefore, as the complexity it takes to describe something increases, a conversational interface’s usability diminishes. While this observation may be true, it’s not very useful.
                            Honestly, my uncertainty at this moment humbles me too much to prognosticate on new design principles. What I can do instead is take a lesson from the recently departed Charlie Munger & invert the problem.
                        DESIGNING BACKWARDS
                            If we try to design the next abstraction layer looking forward, we seem to end up with something like a chatbot. We now know why this is an incomplete solution on its own. What if we look at the problem backward to identify the undesirable outcomes that we want to avoid? Avoiding stupidity is easier than seeking brilliance, after all.
                            An obvious mistake to steer clear of is forcing users to engage in conversations without considering time constraints. When the time is right to chat, it should be in a manner that doesn’t replace existing usability problems with equally frustrating new ones. For basic tasks of equivalent importance to delivering pizza, we should find practical solutions not of equivalent extravagance to driving a Lamborghini. Furthermore, we ought not to impose prompt engineering expertise as a requirement for non-expert users. Lastly, as systems become more human-like, they should not inherit our gullibility, lest our efforts inadvertently optimize for exponentially easier access to our private data.
                            A more intelligent interface won’t make those stupid mistakes.

                    Case Study Option 2:
                    - cardHeader: Using Friction As A Feature In Machine Learning Algorithms
                    - cardDescription: In this article for Smashing Magazine, I discuss how friction often has a negative connotation in user experience design, but it actually has many benefits. Its best-known use case is mitigating unintended consequences in high-risk scenarios, yet it has a new place in the age of artificial intelligence.
                    - cardURL: https://www.smashingmagazine.com/2023/08/friction-feature-machine-learning-algorithms/ 
                    - Content: 
                        This article was published in Smashing Magazine.
                        A common assumption in user experience design is less friction makes apps more delightful. But in practice, the happy path isn’t always the smoothest. The term “friction” in the digital sense usually refers to anything that makes experiences cumbersome. It’s an analogy to the physical resistance that occurs when objects interact. Digital friction comes in many forms, from frustrating flows to confusing copy. But plenty of scenarios actually benefit with a bit of resistance. Its killer feature is mitigating unintended consequences, such as an accidental Alexa shopping spree.
                        You’ve likely already encountered intentional friction many times. Most apps leverage it for destructive actions, account security, and error handling, as recommended by experts from Norman Nielsen Group to the magazine you’re currently reading.
                        Yet friction has found a new calling in the age of artificial intelligence. When implemented correctly, it can improve the efficiency of AI systems such as machine learning algorithms. These algorithms are often used to personalize experiences through predictive recommendations. Some applications incorporating these algorithms realize that adding a bit of friction to their interface can turn each user interaction into an opportunity to improve algorithmic quality.
                        While less friction makes an app smoother, a bit more may make it even smarter.
                        Friction As A Feature
                            Before venturing down the AI rabbit hole, let’s explore some simple examples showcasing the basic benefits of friction in UX. These are a helpful foundation to build off as we ascend into more complex applications for machine learning algorithms. Regardless of your familiarity, this will ground the following lessons in first principles.
                        PREVENTING UNINTENDED CONSEQUENCES
                            A common use for friction is error prevention, the fifth entry in Jakob Nielsen’s list of usability heuristics. In scenarios with the potential for high-cost errors, such as irreversible deletion, apps often request confirmation before executing requests. Confirmations often display in a modal, locking the rest of the screen to increase focus on copy explaining an action’s implications. This extra step provides some extra time to consider these ramifications.
                            “By forcing us to slow down and think at this exact moment, we’re kept from making potentially disastrous decisions by accident.” — Archana Madhavan in Amplitude’s “Onboarding With The IKEA Effect: How To Use UX Friction To Build Retention”
                            Sometimes more resistance is present when the consequences can be catastrophic. For instance, a confirmation may involve cognitive work such as typing “DELETE” to submit a deletion request. This level of resistance makes sense when considering the humbling fact of life from Steve Krug’s classic UX book Don’t Make Me Think, which states, “We don’t read pages. We scan them.” This makes it easy to imagine how a streamlined design can make it too easy to overlook the consequences of a click.
                            While these tactics may look comically cumbersome, they mitigate devastating downsides. This use of friction is like a train’s brakes screeching to a halt right in time to avoid a collision — everyone breathes a sigh of relief, crisis averted. This also outlines the basic framework for understanding when to add friction. It boils down to a cost-benefit analysis: do the rewards of streamlining outweigh the risk? If not, slow it down. Now let’s move on from a black & white example to venture into a grayer area.
                        NUDGING TOWARD HEALTHY BEHAVIOR
                            Some problems aren’t classifiable as errors but still aren’t in anyone’s best interest. Trying to solve them becomes wicked because there is no right or wrong solution. Yet that doesn’t make failing to address them any less of an existential risk. Consider social media’s medley of knee-jerk, tribalistic behavior. It has led many to question the value of these apps altogether, which isn’t good for business, or society at large. In an attempt to encourage more thoughtful discourse, these platforms turn to friction.
                            Twitter explored adding an extra step that asks people to read articles before retweeting them. This nudge aims to craft a more trustworthy experience for everyone by slowing the spread of misinformation. According to their reporting, people shown the prompt opened articles 40% more often, and some decided not to retweet it after all. They built on this success by showing a warning before users post messages which include harmful language.
                            Instagram also implemented a similar feature in its fight against online bullying. Adam Mosseri, the Head of Instagram, published a blog post stating that this “intervention gives people a chance to reflect.” Although specific data isn’t provided, they suggest it had promising results in cultivating a more humane experience for their communities.
                            These examples show how faster is not always better. Sometimes we need restraint from saying things we don’t mean or sharing things that we don’t understand. Friction helps algorithms in a similar manner. Sometimes they also need more information about us so they don’t recommend things we won’t appreciate.
                        UNDERSTANDING PREFERENCES & OBJECTIVES
                            Let’s shift focus to AI with a simple example of how friction plays a role in machine learning algorithms. You’ve probably signed up for an app that begins by asking you a bunch of questions about your interests. Behind the scenes, an algorithm uses these answers to personalize your experience. These onboarding flows have become so common over the past decade that you may have forgotten a time before apps were smart enough to get to know you.
                            You may have never even questioned why you must go through a preference capture flow before getting to explore content. The value is obvious because no one wants the quickest path to something irrelevant. Many apps are simply in the business of making relevant connections, and these personalization tactics have been one of the best ways to do so. A McKinsey report illuminates this further by reporting that “35 percent of what consumers purchase on Amazon and 75 percent of what they watch on Netflix come from product recommendations based on such algorithms.”
                            “The top two reasons that customers churn are 1) they don’t understand your product, and 2) they don’t obtain any value from it. Customer onboarding can solve both of these issues.” — Christina Perricone in HubSpot’s “The Ultimate Guide to Customer Onboarding”
                            Perhaps these onboarding flows are so familiar that they don’t feel like friction. They may seem like necessary steps to unlock an app’s value. However, that perspective quickly changes for anyone designing one of these flows. The inherent tension lies in attempting to balance the diametrically opposite needs of two parties. On the one hand, an algorithm provides better output relative to its input (although asymptotes exist). Success is a function of maximizing data collection touchpoints, but this tends to result in more steps with more complex questions.
                            In short, the quicker an app makes a recommendation, the more likely it will be wrong. On the other hand, an extremely long onboarding flow is unlikely to make an amazing first impression on new users. I had the pleasure of walking this tightrope when designing the onboarding flow at Headliner. Each new step we added always felt like it would be the straw that broke the camel’s back. We nervously monitored our activation reports for signs we went too far but surprisingly saw no meaningful dropoff. Yet, even a slight decrease would easily be worth the improved retention that personalization yielded.
                            The Product Design Manager at Stitch Fix, Deanna Alcorn, documented their process of working through this. The tension is clearly illustrated when she asks the question, “How do we get customers to evaluate as many images as possible while keeping it fun and fast?”. While their case study is a great reference, the right solution will be different for every app. Your onboarding flow should follow the needs of your algorithm while balancing the needs of your users.
                            With that said, there is one app that is legendary for its rapid personalization, and surprisingly, it doesn’t have any onboarding flow at all.
                        Giving An Algorithm Glasses
                            TikTok’s personalization is so good that the New York Times compares it to mind reading. But after signing up for their service, you can just start browsing! In stark contrast, Instagram has multiple onboarding steps without the same algorithmic reputation. How can TikTok have such an advantage if it doesn’t even ask you what you want to see?
                            This is thanks to some clever interface innovations. TikTok’s design turns user engagement into clear signals they use to tweak their algorithms. Content recommendation quality is a direct function of this, which some refer to as an algorithm’s vision.
                        ENGAGEMENT SIGNALS
                            Every interaction is an opportunity to improve understanding through bidirectional feedback. An interface should provide system feedback to the user engaging with it while also reporting to the system how performance meets user expectations. Everything from button taps to the absence of action can become a signal. Interfaces that successfully incorporate this are referred to as algorithm-friendly.
                            A study by Apple’s Machine Learning Research Department details their success in leveraging engagement signals, which they believe “provide strong indications of a user’s true intent,” to efficiently train a machine learning model through a process called Reinforcement Learning from Human Feedback. Their results documented “significant accuracy gains in a production deep learning system,” meaning that an interface designed well enough to analyze naturally occurring user behavior is all that is needed to create personalization that feels like mind reading.
                            Instagram actually employs this strategy as well, although its approach is a bit less cohesive since they seem to be in a perpetual state of transition.
                        TIKTOKIFICATION
                            But what exactly makes an interface algorithm-friendly? In TikTok’s case, it was the design decision to only show one video at a time. That’s right, friction! By decreasing the information density in the viewport at any given time, they increased their understanding of a user’s focus. This localizes interactions (or lack thereof) to specific content as quality measures.
                            Gustav Söderström, the Co-President, CPO & CTO at Spotify has referred to this approach as “giving the algorithm glasses.” Compare this to the medley of distractions in other feeds, and it’s easy to imagine which one is better at collecting data.
                            As we return to my aforementioned framework for evaluating when to add friction, we can understand how it makes sense in this scenario. While each interaction may take slightly longer, relevant content can be found quicker. The trade-off makes sense since relevance sits atop a user’s hierarchy of needs.
                            Additionally, if you were to measure friction over a longer time horizon, you likely would find an experience with better personalization feels more frictionless. This is because the efficiency in helping users find what they’re looking for would consistently compound (although, again, asymptotes exist). So each subsequent visit theoretically requires less work on the user’s part, which makes the alternate approach look like the cumbersome one.
                            “The secret of why some of these products are so good at recommendations is not actually that they have better algorithms. It’s the same algorithms with a more efficient user interface.” — Gustav Söderström in The Verge’s “Why Spotify wants to look like TikTok”
                            While TikTok popularized this interface, anybody who was single in the last decade may notice a similarity to dating apps. Using directional gestures as engagement signals dates back to the swipeable card paradigm Tinder introduced in 2012. They, too, limited the viewport to one result at a time and used actions to inform subsequent recommendations. But TikTok took it mainstream since not everyone needs a dating app, and those who do will churn once they’ve met someone.
                            The results of using this paradigm in everyday entertainment led many platforms to copy it in hopes of the same algorithmic gains. The latest to embark on this journey is Spotify, much to the chagrin of their users. In fact, this decision even landed it on Mashable’s list of worst app updates in 2023. But Söderström says they don’t have a choice, and he believes in the long run, the signal clarity will make up for any interim backlash because of how much quicker it can learn user preferences. Critics fail to realize how important these changes are for Spotify’s future.
                        MAKING LEMONADE
                            The reason this approach is so powerful is due to the compounding nature of good data. Optimizing signals for any individual user creates a data network effect that benefits everyone else. It even turns negatives into positives! An individual bad experience can mitigate others from encountering the same, making the system antifragile.
                            This approach dates back to 2003 with the introduction of Amazon’s item-to-item collaborative filtering. You may know it as “customers who viewed this also viewed this.”
                            This type of filtering produces high-quality recommendations with limited user data. It does so by building relationships between items to proxy user preferences. With only two to three data points, an algorithm can draw connections across the entire dataset. It effectively piggybacks off previous patterns that are similar enough.
                            This means an app like TikTok only needs a few swipes before it can make high-probability assumptions about your preferences. That’s why friction is so useful in algorithm-friendly interfaces. If the initial interactions send clean signals, then an algorithm can graph a user’s interests almost immediately.
                        Friction In The Future
                            We began in the past by reviewing how friction found its way into UX toolkits through error prevention and healthy nudges. Then we moved on to its ability to help algorithms learn user preferences and objectives. While explicit onboarding flows are still in vogue, TikTok is popularizing an interface that makes them unnecessary by using implicit engagement signals leading to significant algorithmic gains. Yet the machine learning age is just beginning, and friction is only accelerating its evolution.
                        INVERTING THE PARETO PRINCIPLE
                            We’ve focused on algorithms that recommend content, but more diverse uses of personalization may emerge due to the newfound capabilities of Large Language Models. These models unlock the ability to manipulate unstructured data at scale. This allows engagement patterns of greater complexity to be analyzed and productized. The result is algorithms can recommend much more than media and metadata.
                            Perhaps they can craft completely personalized feature sets based on our preferences and objectives. Imagine selecting effects in Photoshop and seeing suggestions such as “Creators who used this effect also used this one.” These capabilities could increase the usage of buried features that only power users tend to find.
                            Microsoft is exploring this by adding Copilot to its products. They claim the “average person uses less than 10% of what PowerPoint can do,” but AI will unlock all that latent value.
                            Using LLMs to create feature recommendation engines is a fascinating idea. It would allow developers to stop relying on the Pareto Principle for prioritization. Especially because Joel Spolsky claims the 80⁄20 rule is actually a myth.
                            “A lot of software developers are seduced by the old “80/20” rule. It seems to make a lot of sense: 80% of the people use 20% of the features… Unfortunately, it’s never the same 20%. Everybody uses a different set of features.” — Joel Spolsky in “Strategy Letter IV: Bloatware and the 80/20 Myth”
                            It would be nice if irreducible simplicity in interface design were only a power law away, but feature creep is hard to combat when different people find value in different options. It’s unrealistic to believe that there is some golden 20% of features driving 80% of value. If there was, then why isn’t the Pareto Principle ever applied to content?
                            I can’t imagine a team at YouTube suggesting that removing 80% of videos would improve the service. Instead, it’s viewed as a routing problem: find the right piece of content for the right person. If machine learning algorithms can recommend features, I hope the value of friction goes without saying at this point. The efficiency gains unlocked by algorithm-friendly interfaces absolutely apply.
                        HALLUCINATIONS OR CREATIONS
                            The recent inflection point in the capability of LLMs unlocks an entirely new computing paradigm. The legendary UX researcher Jakob Nielsen believes it introduces the first new UI paradigm in 60 years, which he calls Intent-Based Outcome Specification. Instead of telling computers what to do, we now explain an outcome so they can determine how to achieve it.
                            Using machine learning algorithms to recommend features is one example. Another fairly new example that you’re likely familiar with is chatbots like ChatGPT. Hundreds of millions of people already use it, which is a testament to how out of this world the experience is. Yet therein lies a problem: sometimes its responses literally aren’t grounded in reality because it has a tendency to make them up! This isn’t obvious to those unfamiliar with the technology’s inner workings since there aren’t many safeguards. As a result, some people become dangerously overreliant on its unverified output.
                            In one case, a lawyer based legal arguments on research from ChatGPT only to find out in court that multiple cited sources turned out to be completely nonexistent. The lawyer’s defense was that he was “unaware of the possibility that its content could be false.” Examples like this reinforce the importance of friction in preventing unintended consequences. While ChatGPT’s empty state mentions its limitations, they obviously aren’t stated explicitly enough for everyone.
                            Extra steps and prompts, such as those mentioned earlier, could better educate users about what is referred to as a “hallucination.” It’s a phenomenon of chatbots confidently outputting responses that don’t align with their training data. Similar to telling a lie when you don’t have a correct answer, although that characterization overly anthropomorphizes the software.
                            Yet some see hallucinations as more of a feature than a bug. Marc Andreessen, the co-founder of Netscape, states during an interview that “another term for hallucination is just simply creativity.” He views it as a significant evolution from the hyperliteral systems of the past because they can now brainstorm and improvise.
                            The problem is that chatbot interfaces tend to be simplistic by attempting to be one size fits all. More controls or modes would educate users about available output types so they can specify which they expect. Sometimes we may want an imaginative response from a creative partner. Other times we want the hyper-accuracy of a deterministic calculator, such as ChatGPT’s Wolfram plugin.
                            Perhaps a creativity slider or persona selector similar to Maggie Appleton’s exploration will better align the system to user needs. However it’s implemented, a bit of friction can maximize benefits while minimizing risks.
                        Finding Your Friction
                            We’ve covered using friction for simple error prevention to complex algorithm optimizations. Let’s end with a few tips that make implementing it as smooth as possible.
                        PEAK-END RULE
                            When adding resistance to an experience, the Peak-End Rule is a useful psychological heuristic to leverage. It’s rooted in studies by Daniel Kahneman & Amos Tversky, where they found that perception of painful experiences doesn’t tend to correlate with duration. It’s the peak & end of the experience that subjects recall.
                            In practice, experts suggest that delight is a function of positive emotional peaks and rewarding emotional payoffs. Optimizing for the peak & end provides room to shift focus from time spent and steps taken as performance indicators; long and complex experiences can still be delightful if designed correctly.
                        MAPS AREN’T TERRITORIES
                            People experience friction emotionally, but developers see it as a value on a chart. In the same way that a map is not a territory, this ratio is only an approximation of the actual experience. It’s something to consider when evaluating any strategies for adding or removing friction. Since applications are complex ecosystems, any measurements should consider a holistic view. Every step has second-order effects, which makes one-dimensional measurements prone to blind spots.
                            For example, when a wrong file is deleted, the data can’t report people cursing at their computer screen. Nor is it likely to include the context of them opening a new file just to recreate their old file from scratch. The same subjectivity applies to all instances of friction. For instance, are your reports equipped to measure the trade-off of an action that takes longer but results in better data collection? It might increase algorithmic efficiency, which compounds across a neural network.
                            As we’ve discussed, better recommendations tend to yield better retention, which tends to yield more revenue if a business model aligns with usage. Myopic measurements will miss these types of gains, so make sure to analyze friction in a way that really matters.
                        KEEP PUSHING
                            As software is eating the world, AI is eating software. If it’s a paradigm shift as big as social, mobile, or even the web, then applications must adapt or die. If you want to remain competitive in the machine learning age, then don’t fear friction.

                    
                    Case Study Option 3: 
                    - cardHeader: Designing algorithm-friendly interfaces
                    - cardDescription: In this article for UX Collective, I discuss how designers must craft interfaces to empower artificially intelligent experiences as they become commonplace. This article explores how a user interface can become a great tool to separate signal from noise to help algorithms better understand user intent, resulting in greater personalization quality.
                    - cardURL: https://uxdesign.cc/designing-algorithm-friendly-interfaces-84da3ed076a9
                    - Content: 
                        This article was initially published in UX Collective.
                        As artificially intelligent experiences become commonplace, designers must craft interfaces to empower them.
                        A designer must be intricately familiar with her materials. In the past this meant understanding the nuanced properties of woods, metals, printing presses, & eventually pixels. Today’s digital designers must work with a much more intangible material: an algorithm.
                        They were once comparatively simple sets of rules an application followed to accomplish tasks, such as displaying posts by people you follow. Now they’ve evolved with artificial intelligence into infinitely complex fractal processes often beyond human comprehension. They power most of our daily experiences, but the majority of design literature on this new norm focuses on if these robots will replace us. Instead, let’s discuss how designers can better assist engineering counterparts by reframing design decisions to amplify algorithmic performance.
                        User-centered design is no longer enough, the interfaces of the future must be easy for people to use & easy for algorithms to analyze.
                        The needs of algorithms
                            Algorithms are responsible for most content surfaced in our digital products: posts populating social feeds, shopping suggestions in digital carts, & phrase recommendations in email drafts. They succeed by showing us what we want, when we want — just like a helpful assistant or store clerk. Self-proclaimed ‘humanist technologist’ John Maeda explains their goal in his latest book by likening it to the Japanese custom of ‘omotenashi’: anticipating what the customer wants without asking.
                            However, algorithms are not a solo act. They must be harmoniously paired with intelligently crafted interfaces in order to succeed.
                        Purpose & process
                            Most algorithms focus on automatically detecting patterns in data & subsequently making relevant recommendations. This process is achieved by pairing a specific dataset with analysis dimensions to create what is referred to as a model. It’s then trained by continuously feeding in more data over time, resulting in theoretical improvements. The output is often used to personalize a product: customizing each user’s experience.
                            “More personalization in the user experience usually means more relevance for users, which leads to better conversion rates.” Fabricio Teixeira, UX Collective
                            This explains why data is the new gold. But the originality of most companies’ value propositions means there is rarely a robust public dataset readily available to efficiently train their models.
                            Feedback loops & signals
                            To train a novel model, many companies must act like ouroboros by turning their product into a data collection mechanism that simultaneously uses the results to improve itself. Within this feedback loop, relevant user interactions are tracked as data signals: anything from button taps, gestures, or even an absence of action altogether.
                            “The fact that you linger on a particular image longer than the rest can imply you have an interest in it. Or the fact that you have started typing something and then turned around and left the field incomplete indicates hesitation.” John Maeda
                            A well-designed interaction is intuitive but also separates signal from noise.
                        Algorithm-friendly design
                            The term ‘algorithm-friendly design’ was dubbed by Eugene Wei, a product leader formerly at Amazon, Hulu, & Oculus, to describe interfaces that efficiently help train a model:
                            “If the algorithm is going to be one of the key functions of your app, how do you design an app that allows the algorithm to see what it needs to see?”
                            This explains the myriad interactions that exist solely to gauge user sentiment, such as Reddit’s downvoting or Tinder’s card swiping — they’re useless in isolation but very valuable to algorithms.
                        TikTok’s innovative interface
                            As artificial intelligence undergoes breakneck advances in accordance with Huang’s law, more elegant design solutions are emerging to evolve the paradigm of providing algorithmic visibility. Today’s most mythical algorithm, TikTok’s, utilized its interface to quickly unlock troves of user data for highly competitive content recommendations. Counterintuitively, it did so by employing one of design’s deadly sins: adding friction.
                            The design decision to show only one fullscreen video at a time cleanly localizes all signals on how content is received. Compare this to the medley of distractions around content in Instagram’s feed & it’s easy to see the difference in ability to collect good data — which explains Instagram Reels.
                            In most feeds we can swipe with varying degrees of intensity, allowing us to instantaneously skip past tons of content without telling the algorithm why. This convolutes the analysis:
                            - Was this content scrolled past too quickly to register?
                            - Was the preview only partially in frame?
                            - Was there distracting content above or below?
                            Constraining the scroll interaction makes it a highly effective interpreter of user sentiment. The real beauty of this solution is its invisible downvote button: a swipe can be cleanly counted as a negative signal when paired with an absence of positive engagement.
                        Friction removes friction
                            Although this design decision adds friction initially, over time the opposite becomes true. Improved personalization eventually reduces the amount of recurring actions required, thanks to the compounding interest of good data. In this light the traditional approach actually seems much more cumbersome, as Wei exemplifies with Twitter:
                            “If the algorithm were smarter about what interested you, it should take care of muting topics or blocking people on your behalf, without you having to do that work yourself.”
                            A well-designed onboarding flow could easily minimize the perception of upfront friction until the personalization threshold kicks in.
                            The algorithmic observer effect
                            As documentaries like The Social Dilemma trend, many are increasingly suspicious of how apps misuse data & manipulate behavior. Awareness of algorithmic gaze is altering user engagement: some people may hesitate to click certain buttons in fear their signals will be misused, while others may take superfluous actions to confuse nosy algorithms.
                            If users do not trust a product, then a product cannot trust its data.
                        How to introduce an algorithm
                            When Cliff Kuang, the former Director of Product Innovation at Fast Company, interviewed the Microsoft team responsible for building AI into PowerPoint, they shared a key realization:
                            “Unless the human felt some kind of connection to the machine, they’d never give it a chance to work well after it made even one mistake.”
                            This insight came from comparing fully autonomous virtual assistants with others that took initial direction before providing independent suggestions. It turns out that users trust algorithmic experiences they help train, which makes a lot of sense because our evaluation is often subjective & initial suggestions have less user preference to base off.
                            Letting people steer initial decisions satisfies our emotional needs while giving a model enough time to train itself.
                        Transparency as a strategy
                            On the a16z Podcast, Wei highlights TikTok’s decision to make their algorithmic weighting public by adding view counts to hashtags & utilizing content challenges. This incentivizes creators, hoping to achieve outsized views, to align efforts with what the service is amplifying. This behavior was once called gaming an algorithm, but the success of this strategy should reverse that negative connotation. If users willingly fill gaps in datasets when their goals are aligned, we should call that collaboration.
                            Twitter’s CEO is already considering something similar:
                            “Enabling people to choose algorithms created by third parties to rank and filter their content is an incredibly energizing idea that’s in reach.” Jack Dorsey
                            If black box algorithms give us filter bubbles (see Blue Feed, Red Feed) perhaps transparent algorithms can burst them.
                            In conclusion, algorithms still need humans
                            Spotify’s Chief R&D Officer, Gustav Söderström, spoke with Lex Fridman about setting user expectations for song recommendations. When people are in discovery mode (feeling adventurous enough for questionable suggestions) Spotify leads with machine learning. But in contexts with little margin for error, they still rely on human curators because they outperform algorithms:
                            “A human is incredibly smart compared to our algorithms. They can take culture into account & so forth. The problem is that they can’t make 200 million decisions per hour for every user that logs in.”
                            To scale these efforts, they’ve developed a symbiotic relationship called ‘algotorial’ where an algorithm follows a human’s lead—sound familiar? It’s a nice reminder of humanity’s indispensability, as we designers realize that helping algorithms succeed is now part of our job — that is, until they come to take it away from us ;)

                    Case Study Option 4: 
                    - cardHeader: Product, Explained S2E2 - Maximillian Piras, Explained
                    - cardDescription: In this podcast, Jeff Leff & Mike Alcazarin interview me about my role at Headliner where I lead cross-platform UI & UX. Headliner is a video creation tool designed for audio creators to make audio easily shareable across the web by automatically transforming audio clips, like this, into engaging videos. We also talk about the importance of side projects, user research, & the latest podcasting trends.
                    - cardURL: https://play.headliner.app/podcast/1de99e587cbc4afb87a2ae11cad50688/episode/https%3A%2F%2Fpinecast.com%2Fguid%2F25ad7cbb-cfcf-4c8f-b2a9-e9513aca0989
                    - Content: 
                        This is a podcast.
                        Product explain is a show where we talk about products and the company's history
                        Maximilian Piras: Essentially, we operate with, uh, two beliefs that drive our mission. The first is that we don't believe that the web, or the Internet in general, is optimized for audio. Of course, there's destinations that do audio well, where you go and listen to a catalog of something. But if you look at the way people browse the web, the patterns are all really focused on either text or imagery or video.
                        Jeff Lee: Hey, guys. Welcome to product explain, a show where we talk about products and the company's history and strategy behind them. This season, we're inviting folks from in the field, uh, onto the show to dive deeper into the products they love and the history behind them. I'm your first host, Jeff Lee.
                        Mike Alcazarin: And I'm your co host, Mike Alcazarin. Today we're joined by Maximilian Piras, a product designer with headliner video. Headliner is a video creation tool designed for audio creators, making audio easily shareable across the web by automatically transforming audio clips just like this into engaging videos. At headliner, Max leads cross platform UI and Ux. Prior to headline, Max worked in various product design roles at, uh, companies like Simple Habit, eight tracks, and Visualmax. Max, welcome to product explained.
                        Maximilian Piras: Yeah, thank you so much for having me. It's a pleasure to be here. Jeff and Mike. Looking forward to it.
                        Mike Alcazarin: Yeah, absolutely. I know I was telling you before the show, but I'm so jazzed to be talking to someone from headliner, because we use headliner for every single video. I think this is episode 113 114. I'm not sure when we'll release this one. And we've used headliner to publish all of our socials, so it's really cool to get a sneak peek behind the, uh, behind the curtain, for lack of a better word.
                        Max's startup started as a street art project that eventually evolved into entrepreneurship
                        Max, I was looking at your background, and it's really cool journey just on how you landed in product design as a career, and you have a lot of interesting steps and stops along the way. I saw also that one of these stops included you built a niche streetwear brand that ended up getting sold at the new museum in New York. Uh, tell us about the lost cat story.
                        Maximilian Piras: Yeah, absolutely. That's a fun one to start on. Very strange project, very different time in my life, but it was a lot of fun, learned a lot. It started as a personal project that eventually evolved into my first stab at entrepreneurship. It was just an art project at first that I would do on weekends to escape my day job of designing apps. And it was just kind of like a fun thing to get out of the mode of being on a computer and think about things in a different light. It was actually, uh, a street art project at first. I was at the time when street art was having its moment, Shepherd Fairy was blowing up. All those types of artists were just really in vogue, and I was just really excited about the concept of getting art onto the streets in front of people in a super grassroots way without having to deal with a bunch of bureaucracy and all that. And so I just wanted to get involved and make my own project. And I, uh, actually had studied graphic design in school and had been an illustrator my whole life. So I got to put those skills to use as a kind of nice way to get out of the app world and started creating some posters that were hung up around the city. No, uh, comment on how they got hung up. They were up on the wall, and, uh, they were depicting this cartoon cat. And up top, it had the headline that said lost cat. And upon further inspection, you find out that the cat was not actually physically lost, but it was spiritually searching for itself, and so it was mentally lost. And that was just kind of by the time I was super into philosophy and just thought it was kind of a fun way to inject some kind of deeper thinking into people's day by having them stumble across this poster that would have. It had sayings on it. Like, uh, the first one was said, if found, then consider that we're all lost in some sense. And I just thought it was a fun way to kind of get people out of their daily routine and get them to think about things in a different light. And so they were hung up around the city, and I would just kind of watch to see if anybody interacted with them, and people would stop and think about them, and so they would take photos, et cetera. And I just thought it was actually even funner to kind of have the view of people interacting with the art. So I ended up documenting, like, uh, voyeuristically documenting people stopping in front of the posters. 
                        And then those became a photo series that I started posting online. And, uh, it just got a really good response, so I just kind of kept rolling with it and tried to see where I could take it. And eventually it ended up finding its way into shirts, and I started selling them around the city. I brought them first to a skate shop in New York called labor, and that was kind of my MvP. So I was like, well, if people like the posters, maybe they'll like the shirts. Yeah. And the owner of labor was excited about it, so he let me, he put them in there on consignment and they just kind of. They sold out. And I just kind of kept building off that momentum. And eventually, uh, I got them into the new museum, which was a really big milestone, and at this point, turned into an actual company that I was running with two friends of mine who are George Lois, and Jeremy Nakamura. And we were just running out of my apartment. But, um, eventually I came to the conclusion that although we kind of been finding product market fit, I did just start to feel like, um, since, uh, I'm working in tech and kind of leveling up my product knowledge there, I started to realize how much slower clothing is in terms of innovation than something like software. And so the project lost cat that was supposed to be fun, was now becoming actually more stressful than my normal job. I was dealing with logistics, manufacturing.
                        I'm a huge promoter of side projects. Everyone wants to. Sometimes those might shift over time
                        Jeff Lee: Um, I want to dive into a follow up question. So Mike and I are kind of, like, in a lot of the same veins, like, serial side gig people. We like to explore other things outside of work, which it sounds like it's something that you did. Um, and I like that you talked a little bit about how it went from kind of this fun, creative outlet to maybe becoming bigger than you wanted it to be, and you realize you needed to kind of step away. Talk. I'd love to hear about your thoughts on, like, how do you find that balance? Like, are there other things that you've worked on where you started to, like, put in some more of your creative energy and it got you somewhere else, or do you find that these are just intended to be kind of side things, that they'll run its course and then you move on to the next thing?
                        Maximilian Piras: Um, I'm, um, a huge promoter of side projects. Like, I've always got a side project going, and just. Cause I'm kind of a workaholic, so it's at some level, I'm also trying to chill out a little bit.
                        Maximilian Piras: But it's just kind of addictive to get something going and see it. Hopefully it starts taking off. But I think, um, it's a great outlet to just explore different things that you're not able to do during the week, but having, uh, some time to reflect and say, is this actually what I want to do? I think keeping those goals in mind is super useful. And in this case, I just said, well, I really have no interest in working in fashion or creating a clothing brand. Although it sounded cool at first, when you see behind the scenes of what it's actually entails, I think it was kind of like a sober moment to say, okay, I think I've learned enough at this point, and it's time to use this time to, it's a kind of opportunity cost. So I said, okay, I could keep running, like, kind of a little niche streetwear brand or whatever it's shaping up to be, or I could use that time elsewhere. And so I ended up just jumping into animation after that, and which was another kind of side project that took its course. And I also said, okay, well, I've learned animation. This is a lot of fun. I started actually getting some freelance jobs that I would do on the weekends. And I realized as well, like, animation is not what I want to do full time. It's so much work, like kind of a, uh, much less roi than you get in software. And so again, I went back to saying, okay, time to close the lid on this one and spend that time elsewhere. But 100%, I think side projects are, like, a really good resource that people should totally take advantage of and 100% promote them.
                        Jeff Lee: Yeah, sometimes I found the same thing where, uh, I put too many irons in the fire. And then I realized that, like, none of them are really. Somebody gave me the analogy once of like, uh, kicking 100 soccer balls. Like, you're trying to progress all them forward slightly, and ultimately you're like, I need to do less in order to progress them a little bit further. And I need to figure out which ones are providing me the most joy, or sometimes it's monetary value or whatever you're optimizing for. So it's interesting to kind of hear other folks take on what happens when you're exploring a bunch of things, because I think it's really hard. Everyone wants to. If you're kind of like a serial entrepreneur, you're trying to do everything and be the best at everything, but in reality, you have to kind of pick the one or two lanes that you want to be really, really good at. Sometimes those might shift over time. It might not be forever. That you're doing this one thing and kind of kicking ass at it.
                        Um, and I guess like following up on your long line of side projects, I heard that you spent time as a, ah, movie poster designer, so could you tell us a little bit about that? I think that's also, it sounds like kind of similar to the Lost Cat poster idea, which kind of evolved into this art piece and art experience. But tell us about movie poster design specifically.
                        Maximilian Piras: Yeah, absolutely. In the same vein of, you know, during my twenties, just exploring a lot of different avenues. And when I was growing up, I was in love with movies. I still am, but I wanted to be a director when I was a kid and I had my little camera that I was filming little skits with my friends and I eventually skewed into visual art and design and just kind of fell in love with that route. But then, uh, m getting towards my mid twenties, I had started working in tech and was working at an agency, which all they did was banner ads and microsites. And that was kind of my first view of what it meant to be professional in tech. I'd been building websites my whole life, so I knew that I loved building for the web, but just actually work in that context. I kind of had a not super fun intro to it and so I was starting to search for maybe other ways to spend my day and I had this opportunity to start working at, uh, an agency that designed movie posters. And since I came from a love of movies and like, you know, a lot of artists like Saul Bass, who I really loved all the posters they designed, I thought this would be an amazing intersection of my interests. So I tried it out and I quickly found out that it was actually even less creative than doing banner ads and like the most formulaic just churn out the same thing. Factory all my time was pretty much like airbrushing movie stars faces to get their wrinkles out. And I uh, just kind of realize what the whole industry model over there sets it up in a way that there's actually not that much room for creativity because the studio will send out an RFP request for proposal to all these agencies and they're all kind of fighting for the bid and they have very short timelines, so they're just really.
                        Maximilian Piras: Incentivized to do what they know works and they don't have time to like add in psychographics or market analysis and such, so they just kind of churn out something that feels very familiar to everything else. And their goal is to not raise eyebrows. It has to look similar enough, but be a little different. And so, yeah, that ended up uh, being the complete opposite of what I thought it would be. And I started to realize all the posters that I really liked, like Mondo or, you know, the ones that are more creative, like the Saul bass ones, those are probably for smaller releases. You know, they're probably for indie movies that have a very small distribution. And so to be successful in industry as well, you're kind of working in that agency world. And I just kind of came to the conclusion that the web was actually a lot more fun to work on than this. And I hadn't found startups yet, but I was lucky enough to get, lucky enough to get an offer at Ahrefax right after that, which was the first startup I worked at and just totally fell in love with it and was really excited to get back into kind of the freedom of software again. So it was a very similar process of kind of figuring out exactly, uh, diving in to figure out what the nuts and bolts were and realizing it wasn't actually for me. So here I am back in tech.
                        Mike Alcazarin: Yeah, that's a good transition to, to, you know, to hear more about what you're doing today at headliner. And like I said, I'm um, super jazzed to take a peek under the hood because we've been using headliner for the past two years.
                        Headliner is a suite of tools designed to help podcasters extend reach
                        But before we dive into that though, tell our audience, you know, what is headliner?
                        Maximilian Piras: Yeah, for sure. That's super. It's really cool to hear the guys users of it. And this might turn into like a semi usability test. User interviews. So sorry if I start digging into how, you know, how we can improve, et cetera, but I'm always really excited to meet users of the product. Um, so yeah, headliner is a suite of tools that we created to help podcasters extend the reach of their shows. The mission is to increase the audience of any audio by increasing its discoverability across the web. So this is things like making it more searchable in search engines, helping create trailers for it. Essentially we operate with uh, two beliefs that drive our mission. The first is that we don't believe that the web, or the Internet in general, is optimized for audio. Of course there's destinations that do audio well, where you go and listen to a catalog of something. But if you look at the way people browse the web, the patterns are all really focused on either text or imagery or video. And so audio actually doesn't naturally fit into a lot of those patterns. So the work we do at headliner is really focused on figuring out how to optimize audio to be better discoverable in all those modes, like searching or browsing on social. And, uh, the second belief is that it's kind of a byproduct of that. First one is that we don't think that the majority of listeners out there even have a podcast app installed yet. So this has, um, led us to start thinking about how do we find audiences for podcasters in places that aren't currently in vogue. Like, what's the next set of listener, where the next set of listeners going to be? Because we don't think they're in a podcast app. If you look at the stats, podcast consumption is still, although it's growing, it's still so far behind video and other types of media. So, uh, yeah, these beliefs are what drive our product development, and we're just trying to create tools that help podcasters get their audio out there.
                        I wanted to comment on, the web is not built for audio. My wife is a, um, she, every movie that we watch at home has to have clothes closed captions on. And then I used to kind of poke fun at her for it, like, oh, why do you need this? But then we watch Game of Thrones with closed captions on and you have all these very unique names. Uh, I'm sure, uh, um, lord of the Rings is the same way. And you're like, oh, actually this is really helpful because it starts to kind of reinforce. I'm hearing it and seeing it and now I know all the names and what's going on and all that sort of stuff. And I really love that you kind of commented on how people explore the web. I think I stumbled on like listening and watching videos at like two or three x speed now. And it feels like a short, like a, like a superpower when you're like powering through a YouTube video that's normally 30 minutes or whatever. I'm sure people listen to our podcast in two x speed, but that's hopefully that's okay.
                        Headliner is an early stage startup still. It's been around for about five years
                        Uh, I wanted to ask overall, like, it sounds like you've kind of explored a couple different design avenues and kind of landed on tech, and so that's kind of this like mini optimization. And now you're at headliner, what makes product at, or uh, at least designed, or, you know, both at headliner unique in your perspective? Like what makes it super interesting place to work? Like, how is it different than working at maybe some of your previous stops or other places in tech that you've heard about like, tell us a bit more about that.
                        Maximilian Piras: Sure. Yeah. Uh, it's an early stage startup still. It's been around for about five or six years, I believe I joined four years ago, but it's still super small, super scrappy, and I think that's the type of company that really attracts me. I love, as you know, from my background, I kind of was all over the place. I love to just try different things, and so I love to be involved in, uh, all the different avenues as opposed to being siloed or super specialized, uh, in one avenue. So early stage startups always really attracted me, um, just to the lifestyle and kind, um, of the mode of communication they have and kind of the freedom that you have to try new things as long as you have a good reason for it. And obviously, I've always been interested in kind of building things from kind of the ground up, I think, uh, so headliner and eight tracks as well have been the two companies that the best embodied this. And uh, ever since I started on that path, I've just been constantly seeking them out. And I think design at headliner, it's, right now it's just me. So I'm the only designer team of one individual contributor. So, uh, I don't know if that keeps it interesting because I don't know how interesting I think I am. But uh, at the very least, it lets me try a bunch of things. And there's some things that I do probably not great, and there's some things that I think I do differently that could result in interesting things, because there's not any bureaucracy to really stop us from trying it. So right now we're just super biased to action and we just try to ship things and see what happens. And obviously try to ship the right things, but specifically try to ship things that can then give us feedback from our users and from our metrics in terms of telling us if we're going in the right direction. So we're still super early stage. We uh, still have under 20 people on the team, and I think that's a really fun environment. And so I've always gravitated towards them.
                        Headliner is a browser-based video editor for audio creators
                        Mike Alcazarin: So really interesting that it's been around for about six years and you've been there for the majority of life of headliner. I'm curious, how has the company evolved over the past four years? And then a, uh, second question to that that I'll append is, do you know the history of how headliner got 
                        Jeff Lee: That's exciting. Yeah. You talked a lot about initially from audiograms and how that kind of blew up. And now we see them kind of everywhere, right. Especially sometimes I'm scrolling videos and I don't want to. Maybe I'm like, in a public place and I just want to read through what they're saying, or they have bad audio and I can't hear it, and I have to kind of read it as well. It's the other, ah, use case all the way up to, um, kind of this like, AI solution, um, that you're talking about, where you're bringing up, serving up more relevant information, more relevant podcasts through disco.
                        Could you walk us through, like, other interesting, or maybe even some of your favorite short form, like, content trends right now? Like, I'm sure you guys are looking at across the board what people are doing in that space. Anything else that kind of jumps out at you. For example, right now on Instagram, I'm hearing a lot of people using those audio templates, one that comes to mind for some reason. Um, and that wraps up the 2022 season audio clip that people keep. They use it as part of their reels. Um, so I'm curious, what are some things that feel really novel and unique, um, in terms of how people are creating some of their short form content?
                        Maximilian Piras: Sure. Yeah. I mean, it's hard for me to pick a favorite because I'm always just in, like, you know, landscape analysis mode. It's always kind of a mix of there's this. This group of people who effectively think audiograms are no longer working. And again, going back to the ROI discussion, like, it's. There's really no quantifiable metric to that. So I get to. I understand why people come to that conclusion. And then there's people who are still doing and saying, well, it's still working fine. So we still see a lot of people actually, depending on your goal. I think it's, it still works well for a certain set of people. But then there's only people who are transitioning to video, and they're using, uh, you know, YouTube shorts and they're doing full video podcasts like you guys are experimenting with now. I think that's an interesting trend, but I tend to think that there will always be audio first creators, because not everybody wants to create a video. Video is just a lot more work, honestly. We, uh, started doing a video podcast for headliner, and it's just, you know, the additional anxiety of like putting on the right shirt and all that. It's just a totally different game. I think a lot of people who entered podcasting are not going to like that transition, and they'll probably focus back on audio first. Although there'd still be this segment of video creators. But I think a really interesting, uh, trend that I've seen is people using short form video to promote audio episodes.
                        Mike Alcazarin: Yeah, it's interesting that you mentioned that because one of my favorites, um, not favored but like one that's top of mind rather for me is the comedian Burt Kreischer. He has his podcast and he does like little like 32nd snippets of his interviews in video form. And then that'll be like hooked for me to go like, oh, like let's go like watch his podcast that he interviews like Taylor Tomlinson. It's like two comedians talking and shooting the shit, which is super interesting. And I uh, love what you said about like the headliner journey because as you were talking about the pain point of making videos, I was like, man, I really don't want to do that. And I was so happy when headliner started to automate all of the things that I was doing. It was just so many steps along the journey on like every Monday morning. And you know, this whole project for Jeff and I is a side project that we get a lot of joy and fun out of. And so for me, I just wanted to minimize that time because I was finding myself, you know, we posted on Monday mornings. It's like I have to do it before work and so I'm stressing out to get everything all, uh, going and all together. And it's nice to just kind of have headliner pick the 62nd clip. I have everything all set up for it to publish and then I can go and post away. So I really, really appreciate that product. So, yeah, that was super fun. To get a look behind the scenes at headliner, let's dive into our lightning round of questions.
                        I think the worst product I've used is honestly, Apple podcasts
                        So we'll start off with, uh, some fun ones. Um, what is the worst product that you've ever used? And then what's the best product that you've ever used?
                        Maximilian Piras: Yes, this will be interesting. I'm just going to, for the worst product, I'm going to come out with a really hot take. And I'm sure some people disagree with this, but I think the worst product I've used is honestly, Apple podcasts. And that's a really big jab, I'm sure to a lot of people. I actually think the product is pretty good in isolation. Like, the UI is kind of nice the UX is okay. Sometimes it really frustrates me, but overall, I'm okay with it, I guess. But the reason I think it's the worst product is because I just don't believe products exist in isolation from the context of the greater landscape they're in. And given that Apple podcast is the default app on every iPhone, and given that it's still the biggest podcasting app, despite that it's got so many usability problems, it's far from terrible. But there's a lot of apps that do it much better. But they're just using their distribution to get that listenership, and I guess rightfully so, because they essentially created the format. But I think that they're just not keeping up with a lot of the innovation in the industry. And I wish they would because I think given their position, they kind of have a responsibility of being a product from one of the most, the richest company in the world, essentially. I don't know if they still are, but they were at one point, and you'd think that those resources could at least go into bringing, uh, the industry a bit forward further. And the fact that they're still not dethroned yet just kind of adds to it. And I think it just shows they're resting on their laurels. And there's even a bunch of really nice innovations from Adam Curry, who is one of the founders of podcasting along in conjunction with, uh, the folks at Apple. He's been doing a project called podcasting 2.0 with all of these nice open web standard tags, which is just really pushing the user experience further. And Apple doesn't support any of them. So I just think. I'm just really disappointed in the product. Despite that it does some things really well. I think that it's, you know, it really needs to do better as a product, given that it's still leading the industry.
                        Mike Alcazarin: Totally. It's interesting that you mentioned that. No, I think it's spicy. I like it. I'm here for it. But it's so frustrating. From the podcaster create podcasting creator side, where I feel like the metrics and the plumbing is just like terrible. It's so hard to get really strong signals from like, you know, where the hotspots are so you can know where to double down and like, the algorithms for like, how is it popping up into like, where is super, like, opaque? So I think I'm like, even on that back end side of it, it feels very much like a black box to us. So I. And also like what you say about like the UX, because I, whenever I'm like, I'm, I'm an Android in like, Microsoft type of person. Jeff will tease me about my lack of going out to the Apple ecosystem. But whenever I go onto Apple podcasts, uh, to upload the episodes, but to just scan through and grab the links, I feel like I'm back in 2007 ripping CDs onto iTunes from and just, it's like this super gray button, old school uI. But, um, yeah, anyways, that got me going about my feelings on Apple, so that was a good thing for me.
                        Maximilian Piras: Yeah, I think the best product. I mean, this is such a hard one. There's so many great products out there. But I think the product I'm most excited about right now is still Figma. Since I'm designing UI all day. Just the change from Figma to sketch felt ironically identical to the change from Photoshop and illustrator to sketch about ten years ago. In that it just like you were saying, with what we're trying to do at headliners, understand the workflow and try to remove steps that are a pain point and just to simplify the usage of the product and get somebody from a to z quicker or in a more enjoyable way. I think the ways that Figma has done that in terms of really understanding product designers workflows and automating some of the steps, like with the auto layout, even the way prototyping is built in, the way it spits out code so you don't have to go into zeppelin. I think it just took out so many frustrating parts of the process, process that it feels really magical. And to me, that's a measure of a good product, is when you feel like there's some magic behind it. Like you push a button and you're like, oh, my God, that was crazy. That's how I felt with Figma, uh, with their updates over the past two years or so. So I'm going to give it to them.
                        Jeff Lee: Yeah, it's awesome. We absolutely love Figma as well. It's actually how we design some of our episode art. We do it on Figma, just kind of like replacing some things there and, yeah, I wish we could automate some of that too, but, yeah, hopefully. Yeah, exactly.
                        Jeff: I've been trying to get better at decision making
                        Let's say that you were suddenly the top 1% at any one skill or any one thing that, um, in the world. What might that be? I know you've kind of delved in a lot into the design space, but is there maybe something else that you'd be interested in all of a sudden becoming, like, the top 1%.
                        Maximilian Piras: Yeah, I think my answer is kind of vague, but I think it's true. I think if I was in the top percent of anything, it would be top percent of decision makers. I think the power of good decisions in any industry you're in is so powerful. And, uh, no matter how much talent you have in something, if you're not using it with the right decisions, you could be squandering it. So I think just. I've been trying really hard to get better at decision making over the past couple years, just knowing what to do, when to do it, what not to do, risk mitigation, and essentially knowing what problems to focus on, because I really love this saying that I forgot who said, maybe it was Don Dorman or somebody like that. They said a, uh, beautiful solution to the wrong problem is worse than, like, a decent solution to the right problem or even a bad solution to the right problem. So I think decision making is really a superpower that I've been trying to harness more, and hopefully, one day, I'll get into the top 1%, but still working on that.
                        Mike Alcazarin: I love that. Whenever we ask this question, I think of the Bernie Sanders meme, the top 1%. But, um, one thing that one book that I like for decision making that I heard from the Tim Ferriss show that I loved was thinking in bets. I can't remember the author, but it's a really good book. Ah, yeah.
                        Jeff Lee: Um, I just listened to that.
                        Mike Alcazarin: Yeah, thinking in bets. Um, and the story is really cool. It's like, uh, and, Jeff, it's fresher for you, so I'll butcher it. But it's essentially a woman quits grad school, goes to her brother in Montana, and her brother is, like, a professional poker player. And then she just becomes this, like, amazing poker player. But she was, I think, studying something, like, very science heavy in her for her master's degree. And so she ended up going back to that career and kind of, like, you know, funneling in just everything she learned about poker and, like, the odds of, like, making a decision and when you should do that, because there's actually, like, a right decision and a wrong decision for, you know, what cards are on the table if you are keeping track of things. So, anyways, that one was super fascinating for me, and I like that. I think it's pretty quick, too. It's, like, 200 or so pages. But, um, I'd like to four, five.
                        Jeff Lee: Hour listen on, like, a one point hat, like one and a half speed. So that's my measure. I'm not a reader as much as I am a listener, so this is why I'm excited about the audio stuff. If I were to give it like a TLDR, basically, the two main takeaways for me were one, like, never claim that you're 100% sure or unsure about anything. If you say, I'm, um, 60 or 70% sure or unsure, then it opens it up for people to freely disagree with you, which is always a good thing. And then the other thing is mainly around optimized for process, not outcomes. Like, oftentimes people will, like in poker, for example, like, you might play the right hand and you might have an 80% chance to win, and then you could still lose, and people will draw their feedback mechanisms off the outcomes, which is a wrong way to actually get better. At poker, it's mostly about, like, are you making the right decisions? Are you including the right criteria? Um, and then over a long string of time, then you'll be, quote, unquote, at least in poker, like a winner. So kind of the same applies to life and business. Like, making the right decisions via process versus, like, making, like, trying to over optimize on just the outcome was, uh, like, were two of the main takeaways that I was thinking about.
                        Maximilian Piras: Yeah, I love that. It's all really, really interesting. I'll definitely give that a read. And I think that's all spot on. I think that last. That last part about, you know, you. You could win this and. But lose the next. I think that's super important lesson. And I forgot what it's called. I think it's called the Kelly criterion or something, but essentially, it's always making sure you can live to see the next day. So whatever bet you take, don't go all in. As you said, don't go 100%. Just, uh, make sure the outcome of your bet will let you make another bet tomorrow and keep learning. So. I love that advice.
                        Mike Alcazarin: Yeah.
                        If you had to share advice with everyone via a billboard, what would it say
                        And so if you had to share advice with everyone via a billboard, and you could put up a billboard anywhere, what would it say?
                        Maximilian Piras: Oh, yeah, I love this question. So, I actually had to look up one of my favorite quotes to answer with this, and, uh, it's, um. Sorry, maybe not sorry, but Steve Jobs quote, I know, pretty played out. But he said, uh, he had this quote where he said, everything around you that you call life was made up by people that were no smarter than you. And you can change it. And I just thought that was such an empowering, like, insightful, statement to encourage all of us to just build stuff, you know? If we don't like something, let's try to build another one. Let's give feedback. And I just love how it empowers anybody. You don't have to be a designer to. To give me feedback on the design a headliner, happy to hear it. Or design a competitor, and we'll try to out compete it, you know? But I just loved how it empowered people to try to change the world via action. So that's going to be my billboard if I ever put one up.
                        Mike Alcazarin: I love it. Um, we'll leave with that one, um, on all of our social. But where can people find you? Any pluggables or any call to action for our audience?
                        Maximilian Piras: Yeah, sure. Feel free to hit me up on Twitter aximillionnyc, or you can reach me at my website, which is also maximillion NYC. And, uh, I'll plug headliner. I mean, if anybody hasn't heard of it, definitely check it out. If you're a podcaster, if you have heard of it and you have feedback, feel free to shoot it over to me. Maxedeadliner app. I'm always trying to just be in the mix of hearing what people think about it and hopefully using that to improve if possible. We try our best. That's all we can do. So, yeah, that would be my close.
                        Mike Alcazarin: I love it. Uh, well, thanks so much, Max. And I think from the product explained perspective, I'm, um, a huge headliner fan, so really cool to have you on the show. I thought that was an awesome conversation. Yeah, thanks for coming on. So we would love to hear from you, our audience. Let us know if there's any products or product experts that you'd like to see and hear on the show. Feel free to share with us what you think. You can find us on Instagram and twitteroductspodcast. That's p r o d e x podcast.
                        Jeff Lee: Yeah. And if you like the show, be sure to like us and subscribe on your favorite podcast platforms. We're on all of them. Spotify, Apple podcasts, Google podcasts, good pods, et cetera. Let us know who you'd love us to sit down and chat with next and we'll see you next episode.

                    Case Study Option 5: 
                    - cardHeader: Interview with Workspaces.XYZ
                    - cardDescription: Workspaces.XYZ asks me about my home office & my favorite gear. 
                    - cardURL: https://www.workspaces.xyz/p/299-maximillian-piras 
                    - Content:
                        This interview was published in Workspaces.XYZ
                        What is your favorite item in your workspace?
                        My acrylic desk, I love how it’s there when I need it but otherwise feels invisible. It also keeps me organized because there is so little room for anything superfluous. I'm forced to put things back in their place so the desk becomes clear again (literally).
                        How do you spark creativity?
                        I start drawing in my sketchbook because there are no wrong answers. If I draw something stupid I can always erase it. This freedom helps me overcome procrastination. It also lets me explore concepts from all angles before going digital, which still feels a lot more rigid. Most of my best ideas start in my sketchbook, it's always step one.
                        How do you manage work-life balance?
                        I’m blessed & cursed by loving what I do, so I'm not great at keeping work from bleeding into other aspects of my life. Although one trick that has helped is timing myself. Measuring how many hours I put in lets me manage a balance. Once I’ve hit all my deadlines & put in a reasonable amount of hours, I can unplug guilt-free.
                        What do you think is the main benefit of remote work?
                        It definitely improves my physical & mental health. I love blasting music while I work & I take exercise breaks to stay in shape. It also helps my focus. It was much harder to stay in a flow state when I worked in an open office. Now I can turn my music up & silence my notifications to get some deep work done.


                    Case Study Option 6: 
                    - cardHeader: Redesigning a breaking Twitter
                    - cardDescription: As Elon Musk burns down the Twitter we know, will a drastically different user experience emerge from the ashes? In this article published in UX Collective, I explore ways for Twitter to improve its UIUX through a more algorithm-friendly interface & the new possibilities presented by generative AI.
                    - cardURL: https://uxdesign.cc/redesigning-a-breaking-twitter-4521b258e5aa 
                    - Content:
                        This article was initially published in UX Collective.
                        In the midst of the madness known as Elon Musk’s Twitter takeover, I stumbled on something even more captivating than the drama. It was a video of George Hotz poking around Twitter’s code while philosophizing on alternative executions. Out of admiration for the platform, he was speculating on what changes could let it thrive. This led me down a similar path in considering their product design. Were any assumptions overlooked in crafting the user experience? Have useful lessons from the competitive landscape gone un-leveraged? Is Twitter’s beautiful simplicity keeping it interesting or holding it back? As a public company, Twitter was notorious for its inability to ship. This is evident in how little their interface has evolved since launching in 2006. Now it has gone private & the majority of its employees are gone, leading many to believe it will break…
                        “…it was the first public crack in the edifice of Twitter’s code base — a blip on the seismometer that warns of a bigger earthquake to come.” MIT Technology Review, 11.08.2022
                        I’m not too interested in the state of their servers, but I am fascinated by the aftermath of this possibility. Surviving such a breaking point could signify a drastic departure from the past. An invitation for new modes of thinking about the service. Some say in the midst of every crisis lies great opportunity. So as the bird app teeters on the verge of going up in flames, I’m curious about what reincarnations may rise from the ashes like a phoenix.
                        I decided to explore this from three different perspectives:
                        Algorithm: how might an interface update improve the recommendation algorithm at the center of their user experience?
                        Audience: how might they showcase content in a more engaging way to remain competitive with other social media apps like TikTok?
                        Creators: how might new features allow creators to better express themselves, leading to higher quality content on the platform?
                        Exploration 1: algorithmic efficiency
                        As a Twitter algorithm, I want the cleanest understanding of key user actions so that I can use them as input signals to improve relevancy of the content I recommend.
                        It seems like every platform is copying TikTok’s interface & there’s a good reason. TikTok’s success lies in its efficiency for training recommendation algorithms. This is thanks to the clarity with which its interface defines where a user is focusing. A notion of focus enables the backend to localize interactions (or lack thereof) to specific content as measures of quality. I’ve discussed this in depth in an article called Designing Algorithm-friendly Interfaces, so I’ll skip the technical details here. The upshot is that since social media platforms only succeed by engaging users with relevant content, algorithmic efficiency is a massive advantage. So what would happen if Twitter took a similar approach?
                        An algorithm-friendly interface ensures user actions are translated into clean signals for machine learning models to train off. Content recommendation quality is a direct function of this ability, which is referred to as an algorithm’s vision. Improvements in content recommendation lead to better engagement & retention, which correspondingly strengthens the business by providing it with more opportunities to monetize users.
                        This thinking can be applied to Twitter’s core component by introducing a focus state to Tweets. Enhancing backend visibility of how engaging any specific tweet is can drastically enhance the quality of future tweet recommendations. While this change does add friction to the user experience by slowing down the scroll mechanism, the longterm benefits can easily make the tradeoff worth it.
                        A clear example of this paradigm is apparent in comparing TikTok with Instagram, where the content is almost identical. The graphic above, from my previous article on the topic, illustrates the differences in efficiency between the two interfaces.
                        Sometimes the shortest distance to a destination isn’t the most efficient when considering second-order effects.
                        Exploration 2: audience engagement
                        As a consumer of tweets, I want a viewing experience beyond a block of text so the content is even more engaging.
                        Twitter’s beauty lies in its simplicity; a singular block of text. The usability & universality of this form allows a clear thought to shine without any distractions. But let’s be honest, some of us are on Twitter to be distracted… so, could a more visual user experience be more engaging?
                        For the unfamiliar, Twitter’s microblogging experience was born out of SMS (short messaging service). Initially the only way to tweet was via text message. Since the constraints of this protocol shaped the form of a Tweet, it was a logical assumption that the viewing experience should also feel like a text message — if only for skeuomorphic reasons. While that decision made sense decades ago, it’s an interesting assumption to challenge now that support for SMS compatibility is shrinking. While other media is allowed on Twitter, the core feature is still a block of text & that shapes product perception. But with all the text-to-speech & text-to-image AI available today, there’s no longer a technical requirement for a text input to remain a text output.
                        If you consider the latest technological advancements in generative AI alongside the abundance of arguments that video is more engaging than text, do you believe Tweets should still look like text messages? Using text to compete for attention against video is like bringing a knife to a gunfight. Disrupting the core experience may feel sacrilegious to those of us who love the current product, but local maximums must be abandoned in pursuit of a global one — such is the innovator’s dilemma.
                        Sometimes a product’s best strategy is to disrupt itself.
                        Exploration 3: creative expression
                        As a creator of tweets, I want the ability to add emphasis & intonation so that my viewers can better understand the subtle nuances of my statements.
                        I saved the least controversial perspective for last, if only for anchoring. This change seems so simple that there must be a reason why it isn’t available. It’s likely an artifact from Twitter’s SMS origins, so let’s consider text messaging for a second. How many times have you texted something sarcastic only for someone to take it literally? Now, imagine the same thing happening with a message you send to millions of people — not great, Bob! Well, we already invented some pretty useful text controls to communicate tone. They’re called (*sighs deeply*) bold & italic.
                        Text styling is actually absent across all social media & Twitter may have set the precedent. Somewhere in the transition from blogging to microblogging, these controls went missing. It may have been an effort for SMS interoperability, but backwards compatibility is easily solved by using un-styled versions as a fallback. It seems like an asymmetrical change, the ones that are low risk but have potential for high reward. These opportunities are usually no brainers. Especially with validation in the form of third-party websites popping up to serve your users’ needs.
                        That said, I know what you’re thinking… that feature is underwhelming. Let’s leave on a higher note, throw some AI at the problem — the tweets write themselves!
                        Use a Large Language Model like GPT-3 to combat writer’s block & analyze Twitter’s proprietary data so the copy is optimized for trending topics. Isn’t this what we all really want: less work, more reach! What could go wrong by making it even easier to Tweet without thinking…
                        Last word on the bird
                        These explorations are just for fun & probably unrealistic, but I wanted to share them as a reminder to stay open-minded & optimistic. I hope it doesn’t take a breaking point for you to challenge the core assumptions in your app’s user experience. Even a change that seems strange as first can evolve into the killer feature that keeps you out of Twitter-level turmoil.
                        I also hope this article underscores the massive potential many of us feel Twitter still has. If you know anyone working there who may find these ideas interesting, feel free to share. I’m happy if they’re helpful in any capacity because I’m rooting for the phoenix to rise.

                    Case Study Option 7: 
                    - cardHeader: Warmer welcomes in new user onboarding
                    - cardDescription: In this case study on activation, I showcase my work improving new user onboarding flows at 8tracks & Headliner where we were able to significantly increase our activation rates.
                    - cardURL: https://www.figma.com/proto/uEzQoQzs0lLZJvkYkHYFBJ/CS1%3A-AWW-v1?type=design&node-id=114-532&t=hxx58FRNhf97vNdV-8&scaling=contain&page-id=112%3A531&starting-point-node-id=114%3A532&show-proto-sidebar=1&hide-ui=1
                    - Content:
                        New user onboarding case study to increase 8tracks and Headliner's activation metric. This uses the pirate metrics methodology of product design.

                    Case Study Option 8: 
                    - cardHeader: @MaximillianNYC
                    - cardDescription: You can find my on X, my DMs are open.
                    - cardURL: https://x.com/MaximillianNYC
                    - Content: My X posts / tweets about design. People can contact me here.

                    Case Study Option 9: 
                    - cardHeader: Visit my about me page
                    - cardDescription: My background & contact information can be found here.
                    - cardURL: https://www.maximillian.nyc/about.html
                    - Content: All details about my personal information, such as contact information, can be found here. As well as a story of how I started in design ten years ago. For any inquiries you are unsure about, you can refer them to this page.

                    Case Study Option 10: 
                    - cardHeader: Visit my LinkedIn page
                    - cardDescription: My work history & credentials can be found here.
                    - cardURL: https://www.linkedin.com/in/maximilliannyc/
                    - Content: The best place to learn about my work history is my LinkedIn page. My work skills. Where I went to school.

                    Case Study Option 11: 
                    - cardHeader: My illustration work
                    - cardDescription: A collection of my favorite illustrations can be found here.
                    - cardURL: https://www.maximillian.nyc/illo.html
                    - Content: A collection of my illustrations, such as album covers and animations.

                    Case Study Option 12: 
                    - cardHeader: My brand identity work
                    - cardDescription: A collection of my favorite branding work can be found here.
                    - cardURL: https://www.maximillian.nyc/id.html
                    - Content: A collection of my brand identity work, such as logos, typography, branding, graphic design, and icons.

                    Case Study Option 13: 
                    - cardHeader: John's of Bleeker Street
                    - cardDescription: A classic NYC pizza joint founded by Italian immigrant Giovanni "John" Sasso at the turn of the 20th century.
                    - cardURL: https://johnsofbleecker.com/
                    - Content: My favorite food, pizza, in case anyone asks about what I like to eat.
                    
                    Case Study Option 14: 
                    - cardHeader: A music video for Ryuichi Sakamoto
                    - cardDescription: Watch Ryuichi Sakamoto's "Andata (Electric Youth Remix)" official music video, directed by Maximillian Piras and produced by Roast 'n Post.
                    - cardURL: https://www.youtube.com/watch?v=i1JVN3BSmeM 
                    - Content: I created a music video for Ryuichi Sakamoto for a song called Andata that was remixed by Eletric Youth. This song and video was produced by Milan Records and Roast 'n Post.

                    Case Study Option 15: 
                    - cardHeader: A music video for Ryuichi Sakamoto
                    - cardDescription: A classic NYC pizza joint founded by Italian immigrant Giovanni "John" Sasso at the turn of the 20th century.
                    - cardURL: https://www.youtube.com/watch?v=i1JVN3BSmeM 
                    - Content: I created a music video for Ryuichi Sakamoto for a song called Andata that was remixed by Eletric Youth. This song and video was produced by Milan Records.

                    Case Study Option 16: 
                    - cardHeader: Penny Janes Cookies by Julie May
                    - cardDescription: My mom makes amazing custom decorated cookies in NYC for events.
                    - cardURL: https://crumrinecoder.github.io/portfoliotypescript/ 
                    - Content: My mother, Julie May, is a renowned cookie maker. She creates her cookies under the name Penny Jane's Cookies.

                    Case Study Option 17: 
                    - cardHeader: Madisen Holbrook
                    - cardDescription: Learn about Maximillian's girlfriend, the lovely Madisen Holbrook, who is currently doing her postdoctoral research at Columbia.
                    - cardURL: https://hone.me.columbia.edu/people/madisen-holbrook
                    - Content: My girlfriend, Madisen Holbrook, is very beautiful and is currently working as in the Physics lab at Columbia. Madisen began her postdoctoral research in July of 2021.
                    She is currently working on the synthesis and defect control of flux grown TMDs. She is using scanning tunneling microscopy and spectroscopy (STM/S) to characterize the defect species and their electronic properties.
                    Madisen received her Ph.D. in condensed matter physics from the University of Texas at Austin. Madisen’s research focus was the synthesis of two-dimensional materials and the characterization of their electronic properties using STM/S with Prof. Ken Shih. Her dissertation titled “Engineering Two-Dimensional Materials: Discovery, Defects, and Environment” won the Outstanding Dissertation Award from the UT Physics Department.
                    Madisen completed her bachelor’s studies in physics at Lewis &amp; Clark College in Portland, Oregon where she studied gecko adhesion with Prof. Kellar Autumn. Madisen’s hobbies include cooking, art, and spending time with her dog Bijou.

                    Case Study Option 18: 
                    - cardHeader: My GIPHY profile
                    - cardDescription: A bunch of animated GIFs with 2B+ views.
                    - cardURL: https://giphy.com/MaximillianNYC 
                    - Content: I have created animated GIFs with over two billion views and have been commissioned by Giphy/Meta and ACE hotel to create custom animated GIFs.

                    Case Study Option 19: 
                    - cardHeader: My X profile
                    - cardDescription: These days I mostly post about UIUX design & AI.
                    - cardURL: https://x.com/MaximillianNYC 
                    - Content: This is my X profile, which was formerly known as Twitter, where I post frequently about AI and UI UX design.

                    Case Study Option 20: 
                    - cardHeader: My Dribbble profile
                    - cardDescription: A collection of my visual design work.
                    - cardURL: https://dribbble.com/MaximillianNYC
                    - Content: This is my Dribbble profile, which contains many posts of my visual design work. This is a great reference for anyone interested in seeing many examples of my user interface (UI) work.

                    Case Study Option 21: 
                    - cardHeader: My Insta
                    - cardDescription: Mostly just videos of me skateboarding.
                    - cardURL: https://www.instagram.com/maximillian.nyc
                    - Content: This is my Instagram profile.

                    Case Study Option 22: 
                    - cardHeader: My Medium profile
                    - cardDescription: A collection of my older articles on design.
                    - cardURL: https://medium.com/@MaximillianNYC
                    - Content: This is my Medium profile where I have many articles about UI UX design and AI.
                `
            },
            { 
                role: "user", 
                content: `${defineProblem}`
            }],
        temperature: 1,
        max_tokens: 256,
        top_p: 1,
        frequency_penalty: 0,
        presence_penalty: 0
    })

    res.status(200).json({
        AiResponse: completion.choices[0].message.content
    })

}

module.exports = { generateMeta, folioKnowledge }